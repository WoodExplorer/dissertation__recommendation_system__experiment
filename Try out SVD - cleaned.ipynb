{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise import evaluate, print_perf\n",
    "import os\n",
    "import random\n",
    "import datetime\n",
    "#from surprise import BaselineOnly\n",
    "#from surprise import Dataset\n",
    "#from surprise import evaluate\n",
    "from surprise import Reader\n",
    "import collections as coll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_rec(predictions):\n",
    "    rec = coll.defaultdict(list)\n",
    "\n",
    "    for p in predictions:\n",
    "        uid, iid, est = p.uid, p.iid, p.est\n",
    "        #print uid, iid, est\n",
    "\n",
    "        rec[uid].append((iid, est))\n",
    "\n",
    "    for u in rec:\n",
    "        rec[u].sort(key=lambda x: -1 * x[1])\n",
    "\n",
    "    for u in rec:\n",
    "        #print rec[u]\n",
    "        #break\n",
    "\n",
    "        rec[u] = rec[u][:N]\n",
    "    return rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_metrics(test, rec):\n",
    "    starttime = datetime.datetime.now()\n",
    "    hit = 0\n",
    "\n",
    "    all__for_recall = 0\n",
    "    all__for_precision = 0\n",
    "    for user in test.keys():\n",
    "        history = test[user][0]\n",
    "        answer = test[user][1]\n",
    "        tu = [x[0] for x in answer]\n",
    "        rank = rec[user] # self.recommend(history, N)\n",
    "        #print 'rank:', rank\n",
    "        for item, pui in rank:\n",
    "            if item in tu:\n",
    "                hit += 1\n",
    "        all__for_recall += len(tu)\n",
    "        all__for_precision += len(rank) #Note: In book RSP, the author used 'all += N'\n",
    "\n",
    "    metric_recall = None\n",
    "    metric_precision = None\n",
    "    metric_f1 = None\n",
    "    if 0 == all__for_recall:\n",
    "        metric_recall = 0\n",
    "    else:\n",
    "        metric_recall = hit / (all__for_recall * 1.0)\n",
    "\n",
    "    if 0 == all__for_precision:\n",
    "        metric_precision = 0\n",
    "    else:\n",
    "        metric_precision = hit / (all__for_precision * 1.0)\n",
    "\n",
    "    if 0 == all__for_recall or 0 == all__for_precision:\n",
    "        metric_f1 = 0\n",
    "    else:\n",
    "        metric_f1 = 2/(1./metric_precision + 1./metric_recall)\n",
    "\n",
    "    endtime = datetime.datetime.now()\n",
    "    interval = (endtime - starttime).seconds\n",
    "    print 'metric calculation: time consumption: %d' % (interval)\n",
    "    return {'recall': metric_recall, 'precision': metric_precision, 'f1': metric_f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def extract_data_from_file_and_generate_train_and_test(filename, train_percent, seed, delimiter, test_data_inner_ratio, sort_by_time=False):\n",
    "    test = None\n",
    "    train = None\n",
    "    data = {}\n",
    "    random.seed(seed)\n",
    "\n",
    "    with open(filename , 'r') as f:\n",
    "        first_line = f.readline()\n",
    "        for i, line in enumerate(f):\n",
    "            userId, movieId, rating, timestamp = line.split(delimiter)\n",
    "            #userId = int(userId)\n",
    "            #movieId = int(movieId)\n",
    "            rating = float(rating)\n",
    "            timestamp = int(timestamp)\n",
    "\n",
    "            if userId not in data:\n",
    "                data[userId] = []\n",
    "            data[userId].append((movieId, rating, timestamp))\n",
    "\n",
    "    test = {}\n",
    "    train = {}\n",
    "    for userId in data:\n",
    "        total_len = len(data[userId])\n",
    "        if random.random() >= train_percent:\n",
    "        #if 0 == random.randint(0, 2):\n",
    "        #if 2 == random.randint(0, 2):\n",
    "            test[userId] = data[userId]\n",
    "        else:\n",
    "            train[userId] = data[userId]\n",
    "    userId = None\n",
    "\n",
    "    for userId in test:\n",
    "        test[userId].sort(key=lambda x: x[2])\n",
    "    # sort by time: PART 1<begin>\n",
    "    if sort_by_time:\n",
    "        print 'sort by time PART 1'\n",
    "        for userId in train:\n",
    "            train[userId].sort(key=lambda x: x[2])\n",
    "\n",
    "    #print train[train.keys()[0]]\n",
    "    #print test[test.keys()[0]]\n",
    "    #raw_input()\n",
    "    # sort by time: PART 1 <end>\n",
    "\n",
    "    ### split test data further\n",
    "    test_real = {}\n",
    "#    if not sort_by_time:\n",
    "#        for k_user in test:\n",
    "#            test_real[k_user] = [[], []]\n",
    "#            for m, r, t in test[k_user]:\n",
    "#                # every record of test dataset is supposed to be splitted into 2 parts: input part and fact/answer part\n",
    "#                # How to specify the relative of these parts? \n",
    "#                #  Assign num_of_parts_of_test_data an appropriate value: each record of test dataset is supposed\n",
    "#                # to constitute num_of_parts_of_test_data parts, and one of them would serve as the fact/answer part.\n",
    "#                if 0 == random.randint(0, num_of_parts_of_test_data):\n",
    "#                    test_real[k_user][1].append((m, r, t)) # the fact/answer part in one record of test dataset\n",
    "#                else:\n",
    "#                    test_real[k_user][0].append((m, r, t)) # the input part in one record of test dataset\n",
    "#    else: \n",
    "#        # sort by time: PART 2 <start>\n",
    "#        print 'sort by time PART 2'\n",
    "    for k_user in test:\n",
    "        #print 'len(test[k_user]):', len(test[k_user])\n",
    "        #print 'num_of_parts_of_test_data:', num_of_parts_of_test_data\n",
    "        #raw_input()\n",
    "        #print (len(test[k_user]) * (1.0 / num_of_parts_of_test_data))\n",
    "        #print (int)(len(test[k_user]) * (1.0 / num_of_parts_of_test_data))\n",
    "        split_point_index = -1 * ((int)(len(test[k_user]) * test_data_inner_ratio))\n",
    "        #print 'split_point_index:', split_point_index\n",
    "        test_real[k_user] = [test[k_user][:split_point_index], test[k_user][split_point_index:]]\n",
    "        #raw_input()\n",
    "\n",
    "        # sort by time: PART 2 <end>\n",
    "\n",
    "    #print test_real[test_real.keys()[0]]\n",
    "    print 'sort_by_time:', sort_by_time\n",
    "\n",
    "    #raw_input('pause')\n",
    "\n",
    "    return train, test_real\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sort_by_time: False\n"
     ]
    }
   ],
   "source": [
    "data_filename, delimiter, data_set = os.path.sep.join(['ml-1m', 'ratings.dat']), '::', '1M'\n",
    "#data_filename, delimiter = os.path.sep.join(['ml-10M100K', 'ratings.dat']), '::'\n",
    "#data_filename, delimiter, data_set = os.path.sep.join(['ml-100k', 'u.data']), '\\t', '100K'\n",
    "\n",
    "seed = 2 \n",
    "K = 10\n",
    "N = 20\n",
    "train_percent = 0.8\n",
    "test_data_inner_ratio = 0.8\n",
    "train = None\n",
    "test = None\n",
    "original_train, original_test = extract_data_from_file_and_generate_train_and_test(data_filename, train_percent, seed, delimiter, test_data_inner_ratio)\n",
    "#original_train, original_test = extract_data_from_file_and_generate_train_and_test(data_filename, 3, 0, seed, delimiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_file_name = 'tmp__svd_train'\n",
    "test_file_name = 'tmp__svd_test'\n",
    "my_sep = ':'\n",
    "\n",
    "with open(train_file_name , 'w') as f:\n",
    "     # format: userId, movieId, rating, timestamp\n",
    "    for userId in original_train:\n",
    "        for movieId, rating, timestamp in original_train[userId]:\n",
    "            f.write(my_sep.join(map(str, [userId, movieId, rating, timestamp])) + '\\n')\n",
    "    for userId in original_test:\n",
    "        for movieId, rating, timestamp in original_test[userId][0]:\n",
    "            f.write(my_sep.join(map(str, [userId, movieId, rating, timestamp])) + '\\n')\n",
    "\n",
    "with open(test_file_name, 'w') as f:\n",
    "    for userId in original_test:\n",
    "        for movieId, rating, timestamp in original_test[userId][1]:\n",
    "            f.write(my_sep.join(map(str, [userId, movieId, rating, timestamp])) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info of train:\n",
      "6040\n",
      "3698\n",
      "840387\n",
      "info of test:\n",
      "159821\n"
     ]
    }
   ],
   "source": [
    "reader = Reader(line_format='user item rating timestamp', sep=my_sep)\n",
    "\n",
    "data = Dataset.load_from_folds([(train_file_name, test_file_name)], reader=reader)\n",
    "\n",
    "for trainset, testset in data.folds():\n",
    "    first_train, first_test = trainset, testset\n",
    "    \n",
    "print 'info of train:'\n",
    "print first_train.n_users\n",
    "print first_train.n_items\n",
    "print first_train.n_ratings\n",
    "\n",
    "print 'info of test:'\n",
    "print len(first_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n",
      "3706\n"
     ]
    }
   ],
   "source": [
    "all_user_in_test = set([x[0] for x in first_test])\n",
    "print len(all_user_in_test)\n",
    "\n",
    "\n",
    "def extract_all_items(filename, delimiter):\n",
    "    all_items = []\n",
    "    with open(filename , 'r') as f:\n",
    "        first_line = f.readline()\n",
    "        for i, line in enumerate(f):\n",
    "            userId, movieId, rating, timestamp = line.split(delimiter)\n",
    "            \n",
    "            all_items.append(movieId)\n",
    "    return set(all_items)\n",
    "\n",
    "all_item_in_test = None\n",
    "all_items = extract_all_items(data_filename, delimiter)\n",
    "print len(all_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#user_item_interaction = {}\n",
    "#def extract_all_user_item_interaction(filename, delimiter):\n",
    "#    ret = coll.defaultdict(set)\n",
    "#    with open(filename , 'r') as f:\n",
    "#        first_line = f.readline()\n",
    "#        for i, line in enumerate(f):\n",
    "#            userId, movieId, rating, timestamp = line.split(delimiter)\n",
    "#            \n",
    "#            ret[userId].add(movieId)\n",
    "#    return ret\n",
    "#\n",
    "#user_item_interaction = extract_all_user_item_interaction(data_filename, delimiter)\n",
    "\n",
    "user_item_interaction = None\n",
    "user_item_interaction_in_history = {}#coll.defaultdict(dict)\n",
    "for u in original_train:\n",
    "    user_item_interaction_in_history[u] = set([x[0] for x in original_train[u]])\n",
    "for u in original_test:\n",
    "    user_item_interaction_in_history[u] = set([x[0] for x in original_test[u][0]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svd time consumption: 38\n"
     ]
    }
   ],
   "source": [
    "# train SVD\n",
    "\n",
    "starttime = datetime.datetime.now()\n",
    "\n",
    "###\n",
    "# We'll use the famous SVD algorithm.\n",
    "algo = SVD()\n",
    "\n",
    "# train algorithm.\n",
    "algo.train(first_train)\n",
    "\n",
    "###\n",
    "endtime = datetime.datetime.now()\n",
    "interval = (endtime - starttime).seconds\n",
    "print 'svd time consumption: %d' % (interval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function dump in module cPickle:\n",
      "\n",
      "dump(...)\n",
      "    dump(obj, file, protocol=0) -- Write an object in pickle format to the given file.\n",
      "    \n",
      "    See the Pickler docstring for the meaning of optional argument proto.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cPickle as pickle\n",
    "help(pickle.dump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('tmp_svd.algo', 'wb') as f:\n",
    "    pickle.dump(algo, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uid = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#predictions = algo.test([('4', '13', -1)])\n",
    "predictions_without_filtering = None\n",
    "\n",
    "mid = [(uid, iid, -1) for iid in all_items for uid in all_user_in_test]\n",
    "predictions_without_filtering = algo.test(mid)\n",
    "mid = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rec_without_filtering = generate_rec(predictions_without_filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric calculation: time consumption: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'f1': 0.019725711425789216,\n",
       " 'precision': 0.07554166666666666,\n",
       " 'recall': 0.011343941034031822}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_metrics(original_test, rec_without_filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uid = None\n",
    "#predictions = algo.test([('4', '13', -1)])\n",
    "predictions_with_filtering = None\n",
    "\n",
    "#mid = [(uid, iid, -1) for iid in filter(lambda x: x not in user_item_interaction_in_history[uid], all_items) for uid in all_user_in_test]\n",
    "mid = []\n",
    "for uid in all_user_in_test:\n",
    "    mid += [(uid, iid, -1) for iid in filter(lambda x: x not in user_item_interaction_in_history[uid], all_items)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4406656\n"
     ]
    }
   ],
   "source": [
    "print len(mid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_with_filtering = algo.test(mid)\n",
    "mid = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric calculation: time consumption: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'f1': 0.022369587805528203,\n",
       " 'precision': 0.08566666666666667,\n",
       " 'recall': 0.012864392038593176}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_with_filtering = generate_rec(predictions_with_filtering)\n",
    "calculate_metrics(original_test, rec_with_filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
