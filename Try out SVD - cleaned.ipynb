{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise import evaluate, print_perf\n",
    "import os\n",
    "import random\n",
    "import datetime\n",
    "#from surprise import BaselineOnly\n",
    "#from surprise import Dataset\n",
    "#from surprise import evaluate\n",
    "from surprise import Reader\n",
    "import collections as coll\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_rec(predictions):\n",
    "    rec = coll.defaultdict(list)\n",
    "\n",
    "    for p in predictions:\n",
    "        uid, iid, est = p.uid, p.iid, p.est\n",
    "        #print uid, iid, est\n",
    "\n",
    "        rec[uid].append((iid, est))\n",
    "\n",
    "    for u in rec:\n",
    "        rec[u].sort(key=lambda x: -1 * x[1])\n",
    "\n",
    "    for u in rec:\n",
    "        #print rec[u]\n",
    "        #break\n",
    "\n",
    "        rec[u] = rec[u][:N]\n",
    "    return rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_metrics(test, rec):\n",
    "    starttime = datetime.datetime.now()\n",
    "    hit = 0\n",
    "\n",
    "    all__for_recall = 0\n",
    "    all__for_precision = 0\n",
    "    for user in test.keys():\n",
    "        history = test[user][0]\n",
    "        answer = test[user][1]\n",
    "        tu = [x[0] for x in answer]\n",
    "        rank = rec[user] # self.recommend(history, N)\n",
    "        #print 'rank:', rank\n",
    "        for item, pui in rank:\n",
    "            if item in tu:\n",
    "                hit += 1\n",
    "        all__for_recall += len(tu)\n",
    "        all__for_precision += len(rank) #Note: In book RSP, the author used 'all += N'\n",
    "\n",
    "    metric_recall = None\n",
    "    metric_precision = None\n",
    "    metric_f1 = None\n",
    "    if 0 == all__for_recall:\n",
    "        metric_recall = 0\n",
    "    else:\n",
    "        metric_recall = hit / (all__for_recall * 1.0)\n",
    "\n",
    "    if 0 == all__for_precision:\n",
    "        metric_precision = 0\n",
    "    else:\n",
    "        metric_precision = hit / (all__for_precision * 1.0)\n",
    "\n",
    "    if 0 == all__for_recall or 0 == all__for_precision:\n",
    "        metric_f1 = 0\n",
    "    else:\n",
    "        metric_f1 = 2/(1./metric_precision + 1./metric_recall)\n",
    "\n",
    "    endtime = datetime.datetime.now()\n",
    "    interval = (endtime - starttime).seconds\n",
    "    print 'metric calculation: time consumption: %d' % (interval)\n",
    "    return {'recall': metric_recall, 'precision': metric_precision, 'f1': metric_f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def extract_data_from_file_and_generate_train_and_test(filename, train_percent, seed, delimiter, test_data_inner_ratio, sort_by_time=False):\n",
    "    test = None\n",
    "    train = None\n",
    "    data = {}\n",
    "    random.seed(seed)\n",
    "\n",
    "    with open(filename , 'r') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            userId, movieId, rating, timestamp = line.split(delimiter)\n",
    "            #userId = int(userId)\n",
    "            #movieId = int(movieId)\n",
    "            rating = float(rating)\n",
    "            timestamp = int(timestamp)\n",
    "\n",
    "            if userId not in data:\n",
    "                data[userId] = []\n",
    "            data[userId].append((movieId, rating, timestamp))\n",
    "\n",
    "    test = {}\n",
    "    train = {}\n",
    "    for userId in data:\n",
    "        total_len = len(data[userId])\n",
    "        if random.random() >= train_percent:\n",
    "        #if 0 == random.randint(0, 2):\n",
    "        #if 2 == random.randint(0, 2):\n",
    "            test[userId] = data[userId]\n",
    "        else:\n",
    "            train[userId] = data[userId]\n",
    "    userId = None\n",
    "\n",
    "    for userId in test:\n",
    "        test[userId].sort(key=lambda x: x[2])\n",
    "    # sort by time: PART 1<begin>\n",
    "    if sort_by_time:\n",
    "        print 'sort by time PART 1'\n",
    "        for userId in train:\n",
    "            train[userId].sort(key=lambda x: x[2])\n",
    "\n",
    "    #print train[train.keys()[0]]\n",
    "    #print test[test.keys()[0]]\n",
    "    #raw_input()\n",
    "    # sort by time: PART 1 <end>\n",
    "\n",
    "    ### split test data further\n",
    "    test_real = {}\n",
    "#    if not sort_by_time:\n",
    "#        for k_user in test:\n",
    "#            test_real[k_user] = [[], []]\n",
    "#            for m, r, t in test[k_user]:\n",
    "#                # every record of test dataset is supposed to be splitted into 2 parts: input part and fact/answer part\n",
    "#                # How to specify the relative of these parts? \n",
    "#                #  Assign num_of_parts_of_test_data an appropriate value: each record of test dataset is supposed\n",
    "#                # to constitute num_of_parts_of_test_data parts, and one of them would serve as the fact/answer part.\n",
    "#                if 0 == random.randint(0, num_of_parts_of_test_data):\n",
    "#                    test_real[k_user][1].append((m, r, t)) # the fact/answer part in one record of test dataset\n",
    "#                else:\n",
    "#                    test_real[k_user][0].append((m, r, t)) # the input part in one record of test dataset\n",
    "#    else: \n",
    "#        # sort by time: PART 2 <start>\n",
    "#        print 'sort by time PART 2'\n",
    "    for k_user in test:\n",
    "        #print 'len(test[k_user]):', len(test[k_user])\n",
    "        #print 'num_of_parts_of_test_data:', num_of_parts_of_test_data\n",
    "        #raw_input()\n",
    "        #print (len(test[k_user]) * (1.0 / num_of_parts_of_test_data))\n",
    "        #print (int)(len(test[k_user]) * (1.0 / num_of_parts_of_test_data))\n",
    "        split_point_index = -1 * ((int)(len(test[k_user]) * test_data_inner_ratio))\n",
    "        #print 'split_point_index:', split_point_index\n",
    "        test_real[k_user] = [test[k_user][:split_point_index], test[k_user][split_point_index:]]\n",
    "        #raw_input()\n",
    "\n",
    "        # sort by time: PART 2 <end>\n",
    "\n",
    "    #print test_real[test_real.keys()[0]]\n",
    "    print 'sort_by_time:', sort_by_time\n",
    "\n",
    "    #raw_input('pause')\n",
    "\n",
    "    return train, test_real\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sort_by_time: False\n"
     ]
    }
   ],
   "source": [
    "data_filename, delimiter, data_set = os.path.sep.join(['ml-1m', 'ratings.dat']), '::', '1M'\n",
    "#data_filename, delimiter = os.path.sep.join(['ml-10M100K', 'ratings.dat']), '::'\n",
    "#data_filename, delimiter, data_set = os.path.sep.join(['ml-100k', 'u.data']), '\\t', '100K'\n",
    "\n",
    "seed = 2 \n",
    "K = 10\n",
    "N = 20\n",
    "train_percent = 0.8\n",
    "test_data_inner_ratio = 0.8\n",
    "train = None\n",
    "test = None\n",
    "original_train, original_test = extract_data_from_file_and_generate_train_and_test(data_filename, train_percent, seed, delimiter, test_data_inner_ratio)\n",
    "#original_train, original_test = extract_data_from_file_and_generate_train_and_test(data_filename, 3, 0, seed, delimiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_file_name = 'tmp__svd_train'\n",
    "test_file_name = 'tmp__svd_test'\n",
    "my_sep = ':'\n",
    "\n",
    "with open(train_file_name , 'w') as f:\n",
    "     # format: userId, movieId, rating, timestamp\n",
    "    for userId in original_train:\n",
    "        for movieId, rating, timestamp in original_train[userId]:\n",
    "            f.write(my_sep.join(map(str, [userId, movieId, rating, timestamp])) + '\\n')\n",
    "    for userId in original_test:\n",
    "        for movieId, rating, timestamp in original_test[userId][0]:\n",
    "            f.write(my_sep.join(map(str, [userId, movieId, rating, timestamp])) + '\\n')\n",
    "\n",
    "with open(test_file_name, 'w') as f:\n",
    "    for userId in original_test:\n",
    "        for movieId, rating, timestamp in original_test[userId][1]:\n",
    "            f.write(my_sep.join(map(str, [userId, movieId, rating, timestamp])) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info of train:\n",
      "6040\n",
      "3698\n",
      "840387\n",
      "info of test:\n",
      "159821\n"
     ]
    }
   ],
   "source": [
    "reader = Reader(line_format='user item rating timestamp', sep=my_sep)\n",
    "\n",
    "data = Dataset.load_from_folds([(train_file_name, test_file_name)], reader=reader)\n",
    "\n",
    "for trainset, testset in data.folds():\n",
    "    first_train, first_test = trainset, testset\n",
    "    \n",
    "print 'info of train:'\n",
    "print first_train.n_users\n",
    "print first_train.n_items\n",
    "print first_train.n_ratings\n",
    "\n",
    "print 'info of test:'\n",
    "print len(first_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n",
      "3706\n"
     ]
    }
   ],
   "source": [
    "all_user_in_test = set([x[0] for x in first_test])\n",
    "print len(all_user_in_test)\n",
    "\n",
    "\n",
    "def extract_all_items(filename, delimiter):\n",
    "    all_items = []\n",
    "    with open(filename , 'r') as f:\n",
    "        first_line = f.readline()\n",
    "        for i, line in enumerate(f):\n",
    "            userId, movieId, rating, timestamp = line.split(delimiter)\n",
    "            \n",
    "            all_items.append(movieId)\n",
    "    return set(all_items)\n",
    "\n",
    "all_item_in_test = None\n",
    "all_items = extract_all_items(data_filename, delimiter)\n",
    "print len(all_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#user_item_interaction = {}\n",
    "#def extract_all_user_item_interaction(filename, delimiter):\n",
    "#    ret = coll.defaultdict(set)\n",
    "#    with open(filename , 'r') as f:\n",
    "#        first_line = f.readline()\n",
    "#        for i, line in enumerate(f):\n",
    "#            userId, movieId, rating, timestamp = line.split(delimiter)\n",
    "#            \n",
    "#            ret[userId].add(movieId)\n",
    "#    return ret\n",
    "#\n",
    "#user_item_interaction = extract_all_user_item_interaction(data_filename, delimiter)\n",
    "\n",
    "user_item_interaction = None\n",
    "user_item_interaction_in_history = {}#coll.defaultdict(dict)\n",
    "for u in original_train:\n",
    "    user_item_interaction_in_history[u] = set([x[0] for x in original_train[u]])\n",
    "for u in original_test:\n",
    "    user_item_interaction_in_history[u] = set([x[0] for x in original_test[u][0]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svd time consumption: 38\n"
     ]
    }
   ],
   "source": [
    "# train SVD\n",
    "\n",
    "starttime = datetime.datetime.now()\n",
    "\n",
    "###\n",
    "# We'll use the famous SVD algorithm.\n",
    "algo = SVD()\n",
    "\n",
    "# train algorithm.\n",
    "algo.train(first_train)\n",
    "\n",
    "###\n",
    "endtime = datetime.datetime.now()\n",
    "interval = (endtime - starttime).seconds\n",
    "print 'svd time consumption: %d' % (interval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function dump in module cPickle:\n",
      "\n",
      "dump(...)\n",
      "    dump(obj, file, protocol=0) -- Write an object in pickle format to the given file.\n",
      "    \n",
      "    See the Pickler docstring for the meaning of optional argument proto.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cPickle as pickle\n",
    "help(pickle.dump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('tmp_svd.algo', 'wb') as f:\n",
    "    pickle.dump(algo, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uid = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#predictions = algo.test([('4', '13', -1)])\n",
    "predictions_without_filtering = None\n",
    "\n",
    "mid = [(uid, iid, -1) for iid in all_items for uid in all_user_in_test]\n",
    "predictions_without_filtering = algo.test(mid)\n",
    "mid = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rec_without_filtering = generate_rec(predictions_without_filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric calculation: time consumption: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'f1': 0.019725711425789216,\n",
       " 'precision': 0.07554166666666666,\n",
       " 'recall': 0.011343941034031822}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_metrics(original_test, rec_without_filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uid = None\n",
    "#predictions = algo.test([('4', '13', -1)])\n",
    "predictions_with_filtering = None\n",
    "\n",
    "#mid = [(uid, iid, -1) for iid in filter(lambda x: x not in user_item_interaction_in_history[uid], all_items) for uid in all_user_in_test]\n",
    "mid = []\n",
    "for uid in all_user_in_test:\n",
    "    mid += [(uid, iid, -1) for iid in filter(lambda x: x not in user_item_interaction_in_history[uid], all_items)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4406656\n"
     ]
    }
   ],
   "source": [
    "print len(mid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_with_filtering = algo.test(mid)\n",
    "mid = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric calculation: time consumption: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'f1': 0.022369587805528203,\n",
       " 'precision': 0.08566666666666667,\n",
       " 'recall': 0.012864392038593176}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_with_filtering = generate_rec(predictions_with_filtering)\n",
    "calculate_metrics(original_test, rec_with_filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table_name: metrics__chap4_exp4_time_complexity__SVD__N_20__da_1M\n",
      "current train_percent: 0.6\n",
      "sort_by_time: False\n",
      "info of train:\n",
      "6040\n",
      "3680\n",
      "761380\n",
      "info of test:\n",
      "238829\n",
      "len(all_user_in_test): 2432\n",
      "len(all_items): 3706\n",
      "svd training time consumption: 35\n",
      "metric calculation: time consumption: 0\n",
      "svd training time consumption: 61\n",
      "{'recall': 0.015362455983151125, 'precision': 0.07543174342105263, 'f1': 0.025526230654435784}\n",
      "current train_percent: 0.7\n",
      "sort_by_time: False\n",
      "info of train:\n",
      "6040\n",
      "3689\n",
      "789440\n",
      "info of test:\n",
      "210769\n",
      "len(all_user_in_test): 1823\n",
      "len(all_items): 3706\n",
      "svd training time consumption: 35\n",
      "metric calculation: time consumption: 0\n",
      "svd training time consumption: 61\n",
      "{'recall': 0.014233592226560832, 'precision': 0.08228195282501372, 'f1': 0.02426899756905541}\n",
      "current train_percent: 0.8\n",
      "sort_by_time: False\n",
      "info of train:\n",
      "6040\n",
      "3698\n",
      "840388\n",
      "info of test:\n",
      "159821\n",
      "len(all_user_in_test): 1200\n",
      "len(all_items): 3706\n",
      "svd training time consumption: 35\n",
      "metric calculation: time consumption: 0\n",
      "svd training time consumption: 61\n",
      "{'recall': 0.012864392038593176, 'precision': 0.08566666666666667, 'f1': 0.022369587805528203}\n",
      "current train_percent: 0.9\n",
      "sort_by_time: False\n",
      "info of train:\n",
      "6040\n",
      "3700\n",
      "912075\n",
      "info of test:\n",
      "88134\n",
      "len(all_user_in_test): 607\n",
      "len(all_items): 3706\n",
      "svd training time consumption: 35\n",
      "metric calculation: time consumption: 0\n",
      "svd training time consumption: 61\n",
      "{'recall': 0.012957541924796333, 'precision': 0.09406919275123558, 'f1': 0.022777589405030215}\n"
     ]
    }
   ],
   "source": [
    "# for time overhead measuring\n",
    "data_filename, delimiter, data_set = os.path.sep.join(['ml-1m', 'ratings.dat']), '::', '1M'\n",
    "#data_filename, delimiter = os.path.sep.join(['ml-10M100K', 'ratings.dat']), '::'\n",
    "#data_filename, delimiter, data_set = os.path.sep.join(['ml-100k', 'u.data']), '\\t', '100K'\n",
    "\n",
    "seed = 2 \n",
    "N = 20\n",
    "train_percent = 0.8\n",
    "test_data_inner_ratio = 0.8\n",
    "train = None\n",
    "test = None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "table_name_prefix = 'metrics__chap4_exp4_time_complexity__SVD__N_%d__da_%s'\n",
    "\n",
    "cx = sqlite3.connect('my_metrics.db')\n",
    "cur = cx.cursor()\n",
    "\n",
    "table_name = table_name_prefix % (N, data_set)\n",
    "print 'table_name:', table_name\n",
    "cur.execute(\"SELECT name FROM sqlite_master WHERE type='table' AND name='%s';\" % table_name)\n",
    "ret = cur.fetchall()\n",
    "if 0 == len(ret):\n",
    "    sql = '''create table %s (\n",
    "_row_ID integer\tprimary key autoincrement,\n",
    "\n",
    "size integer,\n",
    "min_count integer,\n",
    "window integer,\n",
    "\n",
    "train_percent decimal(30, 28),\n",
    "\n",
    "precision decimal(30, 28),\n",
    "recall decimal(30, 28),\n",
    "f1 decimal(30, 28),\n",
    "\n",
    "train_overhead integer,\n",
    "test_overhead integer,\n",
    "overall_overhead integer,\n",
    "\n",
    "CreatedTime TimeStamp NOT NULL DEFAULT (datetime('now','localtime'))\n",
    ");''' % (table_name)\n",
    "    cur.execute(sql)\n",
    "    cx.commit()\n",
    "\n",
    "#train_percent_list = [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "train_percent_list = [0.6, 0.7, 0.8, 0.9]\n",
    "for i, train_percent in enumerate(train_percent_list):\n",
    "    print 'current train_percent:', train_percent\n",
    "\n",
    "    original_train, original_test = extract_data_from_file_and_generate_train_and_test(data_filename, \n",
    "                                                                               train_percent, \n",
    "                                                                               seed, \n",
    "                                                                               delimiter, \n",
    "                                                                               train_percent)\n",
    "    #original_train, original_test = extract_data_from_file_and_generate_train_and_test(data_filename, 3, 0, seed, delimiter)\n",
    "\n",
    "\n",
    "    train_file_name = 'tmp__svd_train'\n",
    "    test_file_name = 'tmp__svd_test'\n",
    "    my_sep = ':'\n",
    "\n",
    "    with open(train_file_name , 'w') as f:\n",
    "         # format: userId, movieId, rating, timestamp\n",
    "        for userId in original_train:\n",
    "            for movieId, rating, timestamp in original_train[userId]:\n",
    "                f.write(my_sep.join(map(str, [userId, movieId, rating, timestamp])) + '\\n')\n",
    "        for userId in original_test:\n",
    "            for movieId, rating, timestamp in original_test[userId][0]:\n",
    "                f.write(my_sep.join(map(str, [userId, movieId, rating, timestamp])) + '\\n')\n",
    "\n",
    "    with open(test_file_name, 'w') as f:\n",
    "        for userId in original_test:\n",
    "            for movieId, rating, timestamp in original_test[userId][1]:\n",
    "                f.write(my_sep.join(map(str, [userId, movieId, rating, timestamp])) + '\\n')\n",
    "\n",
    "\n",
    "\n",
    "    reader = Reader(line_format='user item rating timestamp', sep=my_sep)\n",
    "\n",
    "    data = Dataset.load_from_folds([(train_file_name, test_file_name)], reader=reader)\n",
    "\n",
    "    for trainset, testset in data.folds():\n",
    "        first_train, first_test = trainset, testset\n",
    "\n",
    "    print 'info of train:'\n",
    "    print first_train.n_users\n",
    "    print first_train.n_items\n",
    "    print first_train.n_ratings\n",
    "\n",
    "    print 'info of test:'\n",
    "    print len(first_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    starttime = datetime.datetime.now()\n",
    "\n",
    "\n",
    "    all_user_in_test = set([x[0] for x in first_test])\n",
    "    print 'len(all_user_in_test):', len(all_user_in_test)\n",
    "\n",
    "\n",
    "    def extract_all_items(filename, delimiter):\n",
    "        all_items = []\n",
    "        with open(filename , 'r') as f:\n",
    "            first_line = f.readline()\n",
    "            for i, line in enumerate(f):\n",
    "                userId, movieId, rating, timestamp = line.split(delimiter)\n",
    "\n",
    "                all_items.append(movieId)\n",
    "        return set(all_items)\n",
    "\n",
    "    all_item_in_test = None\n",
    "    all_items = extract_all_items(data_filename, delimiter)\n",
    "    print 'len(all_items):', len(all_items)\n",
    "\n",
    "\n",
    "    user_item_interaction = None\n",
    "    user_item_interaction_in_history = {}#coll.defaultdict(dict)\n",
    "    for u in original_train:\n",
    "        user_item_interaction_in_history[u] = set([x[0] for x in original_train[u]])\n",
    "    for u in original_test:\n",
    "        user_item_interaction_in_history[u] = set([x[0] for x in original_test[u][0]])\n",
    "\n",
    "\n",
    "    original_train = None\n",
    "    # train SVD\n",
    "\n",
    "\n",
    "    ###\n",
    "    # We'll use the famous SVD algorithm.\n",
    "    algo = SVD()\n",
    "\n",
    "    # train algorithm.\n",
    "    algo.train(first_train)\n",
    "\n",
    "    ###\n",
    "    endtime = datetime.datetime.now()\n",
    "    train_overhead = (endtime - starttime).seconds\n",
    "    print 'svd training time consumption: %d' % (train_overhead)\n",
    "\n",
    "    ########################################################\n",
    "\n",
    "    starttime = datetime.datetime.now()\n",
    "\n",
    "\n",
    "    uid = None\n",
    "    #predictions = algo.test([('4', '13', -1)])\n",
    "    predictions_with_filtering = None\n",
    "\n",
    "    #mid = [(uid, iid, -1) for iid in filter(lambda x: x not in user_item_interaction_in_history[uid], all_items) for uid in all_user_in_test]\n",
    "    \n",
    "    #mid = []\n",
    "    #for uid in all_user_in_test:\n",
    "    #    mid += [(uid, iid, -1) for iid in filter(lambda x: x not in user_item_interaction_in_history[uid], all_items)]\n",
    "    #\n",
    "    #\n",
    "    #predictions_with_filtering = algo.test(mid)\n",
    "    def my_ge():\n",
    "        for uid in all_user_in_test:\n",
    "            for iid in filter(lambda x: x not in user_item_interaction_in_history[uid], all_items):\n",
    "                yield (uid, iid, -1)\n",
    "    predictions_with_filtering = algo.test(my_ge())\n",
    "    mid = None\n",
    "\n",
    "\n",
    "    rec_with_filtering = generate_rec(predictions_with_filtering)\n",
    "    metrics = calculate_metrics(original_test, rec_with_filtering)\n",
    "\n",
    "    endtime = datetime.datetime.now()\n",
    "    test_overhead = (endtime - starttime).seconds\n",
    "    print 'svd testing time consumption: %d' % (test_overhead)\n",
    "\n",
    "    print metrics\n",
    "\n",
    "    precision, recall, f1 = metrics['precision'], metrics['recall'], metrics['f1']\n",
    "\n",
    "    cur.execute('insert into %s (size, min_count, window, train_percent, precision, recall, f1, train_overhead, test_overhead, overall_overhead)' % (table_name) +\n",
    "               \"values (%d, %d, %d, %.19f, %.19f, %.19f, %.19f, %d, %d, %d)\" % (-1, -1, -1, train_percent, precision, recall, f1, train_overhead, test_overhead, train_overhead + test_overhead))\n",
    "\n",
    "    cx.commit()\n",
    "\n",
    "    #break\n",
    "    #break  # for i, (s, mc, w) in enumerate(para_combs):\n",
    "cur.close()\n",
    "cx.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-14f2ee7754da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m [(uid, iid, -1) \n\u001b[1;32m      2\u001b[0m                                             for iid in filter(lambda x: \n\u001b[0;32m----> 3\u001b[0;31m                                                               x not in user_item_interaction_in_history[uid], all_items) \n\u001b[0m\u001b[1;32m      4\u001b[0m                                             for uid in all_user_in_test]\n",
      "\u001b[0;32m<ipython-input-13-14f2ee7754da>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m [(uid, iid, -1) \n\u001b[1;32m      2\u001b[0m                                             for iid in filter(lambda x: \n\u001b[0;32m----> 3\u001b[0;31m                                                               x not in user_item_interaction_in_history[uid], all_items) \n\u001b[0m\u001b[1;32m      4\u001b[0m                                             for uid in all_user_in_test]\n",
      "\u001b[0;31mKeyError\u001b[0m: None"
     ]
    }
   ],
   "source": [
    "[(uid, iid, -1) \n",
    "                                            for iid in filter(lambda x: \n",
    "                                                              x not in user_item_interaction_in_history[uid], all_items) \n",
    "                                            for uid in all_user_in_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for uid in all_user_in_test:\n",
    "    for iid in filter(lambda x: x not in user_item_interaction_in_history[uid], all_items):\n",
    "        (uid, iid, -1) \n",
    "                                            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
