{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gensim#from gensim.models import word2vec\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "from numpy import linalg as la\n",
    "import datetime\n",
    "import time\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.seed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 5]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(set([1,2,3,4,5]), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 5]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter(lambda x: x % 2 == 1, [1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def extract_data_from_file_and_generate_train_set_with_specified_M_and_R(filename, num_of_movies, num_of_rates, delimiter):\n",
    "    train = None\n",
    "    data = []\n",
    "    movie_id = set()\n",
    "\n",
    "    with open(filename , 'r') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            userId, movieId, rating, timestamp = line.split(delimiter)\n",
    "            #userId = int(userId)\n",
    "            #movieId = int(movieId)\n",
    "            rating = float(rating)\n",
    "            timestamp = int(timestamp)\n",
    "            \n",
    "            movie_id.add(movieId)\n",
    "\n",
    "            data.append((userId, movieId, rating, timestamp))\n",
    "\n",
    "    # control number of movies\n",
    "    movies_selected = random.sample(movie_id, num_of_movies)\n",
    "    print 'num_of_movies:'\n",
    "    print 'expected len: %d' % (num_of_movies)\n",
    "    print 'in fact: %d' % len(movies_selected)\n",
    "    \n",
    "    # filter out history records whose movies are not selected\n",
    "    data = filter(lambda x: x[1] in movies_selected, data) # Careful! Hard-coded number!\n",
    "    \n",
    "    # control number of rates\n",
    "    data = random.sample(data, num_of_rates)\n",
    "    print 'num_of_rates:'\n",
    "    print 'expected len: %d' % (num_of_rates)\n",
    "    print 'in fact: %d' % len(data)\n",
    "    \n",
    "    train = {}\n",
    "    for i, t in enumerate(data):\n",
    "        userId, movieId, rating, timestamp = t\n",
    "        if userId not in train:\n",
    "            train[userId] = []\n",
    "        train[userId].append((movieId, rating, timestamp))\n",
    "    \n",
    "    return train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_lines: 1000209\n"
     ]
    }
   ],
   "source": [
    "#data_filename, delimiter, data_set = os.path.sep.join(['ml-100k', 'u.data']), '\\t', '100K'\n",
    "data_filename, delimiter, data_set = os.path.sep.join(['ml-1m', 'ratings.dat']), '::', '1M'\n",
    "#data_filename, delimiter, data_set = os.path.sep.join(['ml-10M100K', 'ratings.dat']), '::', '10M'\n",
    "\n",
    "\n",
    "def get_lines(filename):\n",
    "    cnt = 0\n",
    "    with open(filename , 'r') as f:\n",
    "        for cnt, line in enumerate(f):\n",
    "            pass\n",
    "    return cnt + 1\n",
    "\n",
    "total_lines = get_lines(data_filename)\n",
    "print 'total_lines:', total_lines\n",
    "\n",
    "K = None\n",
    "N = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_of_movies:\n",
      "expected len: 1000\n",
      "in fact: 1000\n",
      "num_of_rates:\n",
      "expected len: 100000\n",
      "in fact: 100000\n"
     ]
    }
   ],
   "source": [
    "num_of_movies = 1000\n",
    "num_of_rates = 10 * 10000\n",
    "r = extract_data_from_file_and_generate_train_set_with_specified_M_and_R(data_filename, num_of_movies, num_of_rates, delimiter)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('3060', 3.0, 959974376),\n",
       " ('1120', 3.0, 956875950),\n",
       " ('1747', 4.0, 959974407),\n",
       " ('296', 2.0, 956875720),\n",
       " ('3108', 4.0, 959974264),\n",
       " ('2124', 3.0, 959974504),\n",
       " ('1213', 3.0, 956875635),\n",
       " ('588', 3.0, 959974349),\n",
       " ('3253', 3.0, 959974328),\n",
       " ('1265', 4.0, 959974264),\n",
       " ('1569', 2.0, 959974560),\n",
       " ('3450', 3.0, 959974504)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.values()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-350337b3b453>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#print [x for x in l]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "l = [[1,2], [3, 4]]\n",
    "#print [x for x in l]\n",
    "x = None\n",
    "print [y for y in x for x in l]\n",
    "print [y for x in l for y in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('3060', 3.0, 959974376),\n",
       "  ('1120', 3.0, 956875950),\n",
       "  ('1747', 4.0, 959974407),\n",
       "  ('296', 2.0, 956875720),\n",
       "  ('3108', 4.0, 959974264),\n",
       "  ('2124', 3.0, 959974504),\n",
       "  ('1213', 3.0, 956875635),\n",
       "  ('588', 3.0, 959974349),\n",
       "  ('3253', 3.0, 959974328),\n",
       "  ('1265', 4.0, 959974264),\n",
       "  ('1569', 2.0, 959974560),\n",
       "  ('3450', 3.0, 959974504)],\n",
       " [('2829', 1.0, 957756760),\n",
       "  ('317', 4.0, 956874389),\n",
       "  ('1641', 3.0, 956873721),\n",
       "  ('3053', 5.0, 957756905),\n",
       "  ('2840', 4.0, 957756905),\n",
       "  ('3253', 3.0, 956873744),\n",
       "  ('3512', 5.0, 956873163)]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in r.values()[:2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('3060', 3.0, 959974376),\n",
       " ('1120', 3.0, 956875950),\n",
       " ('1747', 4.0, 959974407),\n",
       " ('296', 2.0, 956875720),\n",
       " ('3108', 4.0, 959974264),\n",
       " ('2124', 3.0, 959974504),\n",
       " ('1213', 3.0, 956875635),\n",
       " ('588', 3.0, 959974349),\n",
       " ('3253', 3.0, 959974328),\n",
       " ('1265', 4.0, 959974264),\n",
       " ('1569', 2.0, 959974560),\n",
       " ('3450', 3.0, 959974504),\n",
       " ('2829', 1.0, 957756760),\n",
       " ('317', 4.0, 956874389),\n",
       " ('1641', 3.0, 956873721),\n",
       " ('3053', 5.0, 957756905),\n",
       " ('2840', 4.0, 957756905),\n",
       " ('3253', 3.0, 956873744),\n",
       " ('3512', 5.0, 956873163)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#[y for y in x for x in r.values()[:2]] # WRONG!\n",
    "[y for x in r.values()[:2] for y in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "963\n"
     ]
    }
   ],
   "source": [
    "all_tuples = [y for x in r.values() for y in x]\n",
    "distinct_items = set([x[0] for x in all_tuples])\n",
    "print len(distinct_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3922', '3923', '1718', '3925', '3928', '1869', '1147', '3259', '1948', '669']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(distinct_items)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1.12297408e-01,  -3.59947309e-02,   4.36375029e-02,\n",
       "        -6.58282712e-02,  -5.41042387e-02,  -2.02573940e-01,\n",
       "         5.55509552e-02,  -7.79519603e-02,   3.09215277e-01,\n",
       "         2.49680951e-01,   3.67670804e-01,   3.21497858e-01,\n",
       "         9.67275128e-02,  -2.09786549e-01,  -5.31960139e-03,\n",
       "        -1.81605160e-01,  -1.28780171e-01,  -2.49864742e-01,\n",
       "        -1.77400455e-01,   1.84372351e-01,   1.68940768e-01,\n",
       "         2.54767090e-01,   8.53701606e-02,  -1.20013831e-02,\n",
       "         1.35253340e-01,   7.03064725e-02,   2.16806889e-01,\n",
       "        -2.46946931e-01,   1.01544999e-01,  -1.72019288e-01,\n",
       "        -1.32090813e-02,   4.33598049e-02,  -7.59228989e-02,\n",
       "        -3.28450859e-01,   6.33343682e-02,   1.94664538e-01,\n",
       "         8.46228376e-02,   2.02172220e-01,   2.35088378e-01,\n",
       "         2.34534308e-01,  -2.34135330e-01,   5.79590686e-02,\n",
       "         3.68431094e-04,   5.25200069e-02,  -5.04669659e-02,\n",
       "         5.31099504e-03,  -4.69869189e-02,  -2.35796690e-01,\n",
       "         4.84678410e-02,  -1.14225641e-01,  -2.15366498e-01,\n",
       "         1.95508674e-01,   2.07882211e-01,  -1.32640917e-02,\n",
       "        -2.98773646e-02,  -1.88740045e-02,   2.09378779e-01,\n",
       "        -2.18216538e-01,  -2.42468312e-01,   2.22723588e-01,\n",
       "         1.42251700e-01,   1.01911128e-02,  -1.64064970e-02,\n",
       "        -2.69584119e-01,   6.14985172e-03,  -1.31152850e-02,\n",
       "        -2.30130441e-02,  -2.66174287e-01,  -1.11659683e-01,\n",
       "        -1.20146289e-01,   2.46928230e-01,  -2.06637383e-01,\n",
       "        -4.59900238e-02,  -2.20765352e-01,  -5.58300838e-02,\n",
       "        -1.34434059e-01,  -6.97201714e-02,   6.21633716e-02,\n",
       "         1.66741297e-01,  -5.43507747e-03,  -2.93009788e-01,\n",
       "         1.97957143e-01,  -5.57391606e-02,  -1.90795094e-01,\n",
       "        -2.80050069e-01,  -5.45427091e-02,  -3.83489132e-01,\n",
       "        -1.52695984e-01,   3.19632627e-02,   1.73369601e-01,\n",
       "        -2.22963989e-01,   2.24064514e-01,  -1.85206711e-01,\n",
       "         8.23943615e-02,  -1.01023518e-01,  -2.58448929e-01,\n",
       "        -3.95437926e-02,  -2.21037101e-02,   4.54551317e-02,\n",
       "         1.29660591e-01], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m[[x for x in m.wv.vocab][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-01 20:23:22,489 : INFO : collecting all words and their counts\n",
      "2017-04-01 20:23:22,490 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-04-01 20:23:22,498 : INFO : collected 1678 word types from a corpus of 30000 raw words and 5156 sentences\n",
      "2017-04-01 20:23:22,498 : INFO : Loading a fresh vocabulary\n",
      "2017-04-01 20:23:22,503 : INFO : min_count=1 retains 1678 unique words (100% of original 1678, drops 0)\n",
      "2017-04-01 20:23:22,503 : INFO : min_count=1 leaves 30000 word corpus (100% of original 30000, drops 0)\n",
      "2017-04-01 20:23:22,507 : INFO : deleting the raw counts dictionary of 1678 items\n",
      "2017-04-01 20:23:22,507 : INFO : sample=0.001 downsamples 46 most-common words\n",
      "2017-04-01 20:23:22,508 : INFO : downsampling leaves estimated 29029 word corpus (96.8% of prior 30000)\n",
      "2017-04-01 20:23:22,508 : INFO : estimated required memory for 1678 words and 100 dimensions: 2181400 bytes\n",
      "2017-04-01 20:23:22,512 : INFO : resetting layer weights\n",
      "2017-04-01 20:23:22,527 : INFO : training model with 3 workers on 1678 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=1\n",
      "2017-04-01 20:23:22,527 : INFO : expecting 5156 sentences, matching count from corpus used for vocabulary survey\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-01 20:23:23,529 : INFO : PROGRESS: at 11.48% examples, 66440 words/s, in_qsize 4, out_qsize 4\n",
      "2017-04-01 20:23:24,529 : INFO : PROGRESS: at 22.56% examples, 65330 words/s, in_qsize 4, out_qsize 3\n",
      "2017-04-01 20:23:25,529 : INFO : PROGRESS: at 32.75% examples, 63332 words/s, in_qsize 5, out_qsize 1\n",
      "2017-04-01 20:23:26,529 : INFO : PROGRESS: at 42.87% examples, 62167 words/s, in_qsize 1, out_qsize 1\n",
      "2017-04-01 20:23:27,529 : INFO : PROGRESS: at 52.77% examples, 61222 words/s, in_qsize 0, out_qsize 1\n",
      "2017-04-01 20:23:28,529 : INFO : PROGRESS: at 63.17% examples, 61099 words/s, in_qsize 0, out_qsize 1\n",
      "2017-04-01 20:23:29,529 : INFO : PROGRESS: at 74.98% examples, 62171 words/s, in_qsize 2, out_qsize 0\n",
      "2017-04-01 20:23:30,529 : INFO : PROGRESS: at 85.40% examples, 61950 words/s, in_qsize 5, out_qsize 2\n",
      "2017-04-01 20:23:31,529 : INFO : PROGRESS: at 95.80% examples, 61760 words/s, in_qsize 1, out_qsize 4\n",
      "2017-04-01 20:23:31,914 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-01 20:23:31,915 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-01 20:23:31,916 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-01 20:23:31,917 : INFO : training on 600000 raw words (580532 effective words) took 9.4s, 61836 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training finished\n",
      "start modeling\n",
      "modeling finished\n"
     ]
    }
   ],
   "source": [
    "m = train_a_model(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_level_1_dict_level_2_list_of_size_3_tuples_to_list_of_list(data):\n",
    "    return [map(lambda y: y[0], data[x]) for x in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_a_model(para):\n",
    "    data = para['data']\n",
    "    num_features = para['num_features']\n",
    "    min_count = para['min_count']\n",
    "    window = para['window']\n",
    "    para_iter = para['iter']\n",
    "    batch_words = para['batch_words']\n",
    "\n",
    "    #list_of_list = convert_2_level_dict_to_list_of_list(data)\n",
    "    list_of_list = convert_level_1_dict_level_2_list_of_size_3_tuples_to_list_of_list(data)\n",
    "    #print 'list_of_list:', list_of_list\n",
    "\n",
    "    print 'start training'\n",
    "    model = gensim.models.Word2Vec(list_of_list, size=num_features, min_count=min_count, window=window, sg=0, iter=para_iter, batch_words=batch_words)\n",
    "    print 'training finished'\n",
    "    print 'start modeling'\n",
    "    representation = [model[x] for x in model.wv.vocab]\n",
    "    print 'modeling finished'\n",
    "    return model, representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = generate_mimic_data_train_set_with_specified_M_and_R(1000, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " '10',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '17',\n",
       " '18',\n",
       " '19',\n",
       " '20',\n",
       " '21',\n",
       " '22',\n",
       " '23',\n",
       " '24',\n",
       " '25',\n",
       " '26',\n",
       " '27',\n",
       " '28',\n",
       " '29',\n",
       " '30',\n",
       " '31',\n",
       " '32',\n",
       " '33',\n",
       " '34',\n",
       " '35',\n",
       " '36',\n",
       " '37',\n",
       " '38',\n",
       " '39',\n",
       " '40',\n",
       " '41',\n",
       " '42',\n",
       " '43',\n",
       " '44',\n",
       " '45',\n",
       " '46',\n",
       " '47',\n",
       " '48',\n",
       " '49',\n",
       " '50',\n",
       " '51',\n",
       " '52',\n",
       " '53',\n",
       " '54',\n",
       " '55',\n",
       " '56',\n",
       " '57',\n",
       " '58',\n",
       " '59',\n",
       " '60',\n",
       " '61',\n",
       " '62',\n",
       " '63',\n",
       " '64',\n",
       " '65',\n",
       " '66',\n",
       " '67',\n",
       " '68',\n",
       " '69',\n",
       " '70',\n",
       " '71',\n",
       " '72',\n",
       " '73',\n",
       " '74',\n",
       " '75',\n",
       " '76',\n",
       " '77',\n",
       " '78',\n",
       " '79',\n",
       " '80',\n",
       " '81',\n",
       " '82',\n",
       " '83',\n",
       " '84',\n",
       " '85',\n",
       " '86',\n",
       " '87',\n",
       " '88',\n",
       " '89',\n",
       " '90',\n",
       " '91',\n",
       " '92',\n",
       " '93',\n",
       " '94',\n",
       " '95',\n",
       " '96',\n",
       " '97',\n",
       " '98',\n",
       " '99',\n",
       " '100',\n",
       " '101',\n",
       " '102',\n",
       " '103',\n",
       " '104',\n",
       " '105',\n",
       " '106',\n",
       " '107',\n",
       " '108',\n",
       " '109',\n",
       " '110',\n",
       " '111',\n",
       " '112',\n",
       " '113',\n",
       " '114',\n",
       " '115',\n",
       " '116',\n",
       " '117',\n",
       " '118',\n",
       " '119',\n",
       " '120',\n",
       " '121',\n",
       " '122',\n",
       " '123',\n",
       " '124',\n",
       " '125',\n",
       " '126',\n",
       " '127',\n",
       " '128',\n",
       " '129',\n",
       " '130',\n",
       " '131',\n",
       " '132',\n",
       " '133',\n",
       " '134',\n",
       " '135',\n",
       " '136',\n",
       " '137',\n",
       " '138',\n",
       " '139',\n",
       " '140',\n",
       " '141',\n",
       " '142',\n",
       " '143',\n",
       " '144',\n",
       " '145',\n",
       " '146',\n",
       " '147',\n",
       " '148',\n",
       " '149',\n",
       " '150',\n",
       " '151',\n",
       " '152',\n",
       " '153',\n",
       " '154',\n",
       " '155',\n",
       " '156',\n",
       " '157',\n",
       " '158',\n",
       " '159',\n",
       " '160',\n",
       " '161',\n",
       " '162',\n",
       " '163',\n",
       " '164',\n",
       " '165',\n",
       " '166',\n",
       " '167',\n",
       " '168',\n",
       " '169',\n",
       " '170',\n",
       " '171',\n",
       " '172',\n",
       " '173',\n",
       " '174',\n",
       " '175',\n",
       " '176',\n",
       " '177',\n",
       " '178',\n",
       " '179',\n",
       " '180',\n",
       " '181',\n",
       " '182',\n",
       " '183',\n",
       " '184',\n",
       " '185',\n",
       " '186',\n",
       " '187',\n",
       " '188',\n",
       " '189',\n",
       " '190',\n",
       " '191',\n",
       " '192',\n",
       " '193',\n",
       " '194',\n",
       " '195',\n",
       " '196',\n",
       " '197',\n",
       " '198',\n",
       " '199',\n",
       " '200',\n",
       " '201',\n",
       " '202',\n",
       " '203',\n",
       " '204',\n",
       " '205',\n",
       " '206',\n",
       " '207',\n",
       " '208',\n",
       " '209',\n",
       " '210',\n",
       " '211',\n",
       " '212',\n",
       " '213',\n",
       " '214',\n",
       " '215',\n",
       " '216',\n",
       " '217',\n",
       " '218',\n",
       " '219',\n",
       " '220',\n",
       " '221',\n",
       " '222',\n",
       " '223',\n",
       " '224',\n",
       " '225',\n",
       " '226',\n",
       " '227',\n",
       " '228',\n",
       " '229',\n",
       " '230',\n",
       " '231',\n",
       " '232',\n",
       " '233',\n",
       " '234',\n",
       " '235',\n",
       " '236',\n",
       " '237',\n",
       " '238',\n",
       " '239',\n",
       " '240',\n",
       " '241',\n",
       " '242',\n",
       " '243',\n",
       " '244',\n",
       " '245',\n",
       " '246',\n",
       " '247',\n",
       " '248',\n",
       " '249',\n",
       " '250',\n",
       " '251',\n",
       " '252',\n",
       " '253',\n",
       " '254',\n",
       " '255',\n",
       " '256',\n",
       " '257',\n",
       " '258',\n",
       " '259',\n",
       " '260',\n",
       " '261',\n",
       " '262',\n",
       " '263',\n",
       " '264',\n",
       " '265',\n",
       " '266',\n",
       " '267',\n",
       " '268',\n",
       " '269',\n",
       " '270',\n",
       " '271',\n",
       " '272',\n",
       " '273',\n",
       " '274',\n",
       " '275',\n",
       " '276',\n",
       " '277',\n",
       " '278',\n",
       " '279',\n",
       " '280',\n",
       " '281',\n",
       " '282',\n",
       " '283',\n",
       " '284',\n",
       " '285',\n",
       " '286',\n",
       " '287',\n",
       " '288',\n",
       " '289',\n",
       " '290',\n",
       " '291',\n",
       " '292',\n",
       " '293',\n",
       " '294',\n",
       " '295',\n",
       " '296',\n",
       " '297',\n",
       " '298',\n",
       " '299',\n",
       " '300',\n",
       " '301',\n",
       " '302',\n",
       " '303',\n",
       " '304',\n",
       " '305',\n",
       " '306',\n",
       " '307',\n",
       " '308',\n",
       " '309',\n",
       " '310',\n",
       " '311',\n",
       " '312',\n",
       " '313',\n",
       " '314',\n",
       " '315',\n",
       " '316',\n",
       " '317',\n",
       " '318',\n",
       " '319',\n",
       " '320',\n",
       " '321',\n",
       " '322',\n",
       " '323',\n",
       " '324',\n",
       " '325',\n",
       " '326',\n",
       " '327',\n",
       " '328',\n",
       " '329',\n",
       " '330',\n",
       " '331',\n",
       " '332',\n",
       " '333',\n",
       " '334',\n",
       " '335',\n",
       " '336',\n",
       " '337',\n",
       " '338',\n",
       " '339',\n",
       " '340',\n",
       " '341',\n",
       " '342',\n",
       " '343',\n",
       " '344',\n",
       " '345',\n",
       " '346',\n",
       " '347',\n",
       " '348',\n",
       " '349',\n",
       " '350',\n",
       " '351',\n",
       " '352',\n",
       " '353',\n",
       " '354',\n",
       " '355',\n",
       " '356',\n",
       " '357',\n",
       " '358',\n",
       " '359',\n",
       " '360',\n",
       " '361',\n",
       " '362',\n",
       " '363',\n",
       " '364',\n",
       " '365',\n",
       " '366',\n",
       " '367',\n",
       " '368',\n",
       " '369',\n",
       " '370',\n",
       " '371',\n",
       " '372',\n",
       " '373',\n",
       " '374',\n",
       " '375',\n",
       " '376',\n",
       " '377',\n",
       " '378',\n",
       " '379',\n",
       " '380',\n",
       " '381',\n",
       " '382',\n",
       " '383',\n",
       " '384',\n",
       " '385',\n",
       " '386',\n",
       " '387',\n",
       " '388',\n",
       " '389',\n",
       " '390',\n",
       " '391',\n",
       " '392',\n",
       " '393',\n",
       " '394',\n",
       " '395',\n",
       " '396',\n",
       " '397',\n",
       " '398',\n",
       " '399',\n",
       " '400',\n",
       " '401',\n",
       " '402',\n",
       " '403',\n",
       " '404',\n",
       " '405',\n",
       " '406',\n",
       " '407',\n",
       " '408',\n",
       " '409',\n",
       " '410',\n",
       " '411',\n",
       " '412',\n",
       " '413',\n",
       " '414',\n",
       " '415',\n",
       " '416',\n",
       " '417',\n",
       " '418',\n",
       " '419',\n",
       " '420',\n",
       " '421',\n",
       " '422',\n",
       " '423',\n",
       " '424',\n",
       " '425',\n",
       " '426',\n",
       " '427',\n",
       " '428',\n",
       " '429',\n",
       " '430',\n",
       " '431',\n",
       " '432',\n",
       " '433',\n",
       " '434',\n",
       " '435',\n",
       " '436',\n",
       " '437',\n",
       " '438',\n",
       " '439',\n",
       " '440',\n",
       " '441',\n",
       " '442',\n",
       " '443',\n",
       " '444',\n",
       " '445',\n",
       " '446',\n",
       " '447',\n",
       " '448',\n",
       " '449',\n",
       " '450',\n",
       " '451',\n",
       " '452',\n",
       " '453',\n",
       " '454',\n",
       " '455',\n",
       " '456',\n",
       " '457',\n",
       " '458',\n",
       " '459',\n",
       " '460',\n",
       " '461',\n",
       " '462',\n",
       " '463',\n",
       " '464',\n",
       " '465',\n",
       " '466',\n",
       " '467',\n",
       " '468',\n",
       " '469',\n",
       " '470',\n",
       " '471',\n",
       " '472',\n",
       " '473',\n",
       " '474',\n",
       " '475',\n",
       " '476',\n",
       " '477',\n",
       " '478',\n",
       " '479',\n",
       " '480',\n",
       " '481',\n",
       " '482',\n",
       " '483',\n",
       " '484',\n",
       " '485',\n",
       " '486',\n",
       " '487',\n",
       " '488',\n",
       " '489',\n",
       " '490',\n",
       " '491',\n",
       " '492',\n",
       " '493',\n",
       " '494',\n",
       " '495',\n",
       " '496',\n",
       " '497',\n",
       " '498',\n",
       " '499',\n",
       " '500',\n",
       " '501',\n",
       " '502',\n",
       " '503',\n",
       " '504',\n",
       " '505',\n",
       " '506',\n",
       " '507',\n",
       " '508',\n",
       " '509',\n",
       " '510',\n",
       " '511',\n",
       " '512',\n",
       " '513',\n",
       " '514',\n",
       " '515',\n",
       " '516',\n",
       " '517',\n",
       " '518',\n",
       " '519',\n",
       " '520',\n",
       " '521',\n",
       " '522',\n",
       " '523',\n",
       " '524',\n",
       " '525',\n",
       " '526',\n",
       " '527',\n",
       " '528',\n",
       " '529',\n",
       " '530',\n",
       " '531',\n",
       " '532',\n",
       " '533',\n",
       " '534',\n",
       " '535',\n",
       " '536',\n",
       " '537',\n",
       " '538',\n",
       " '539',\n",
       " '540',\n",
       " '541',\n",
       " '542',\n",
       " '543',\n",
       " '544',\n",
       " '545',\n",
       " '546',\n",
       " '547',\n",
       " '548',\n",
       " '549',\n",
       " '550',\n",
       " '551',\n",
       " '552',\n",
       " '553',\n",
       " '554',\n",
       " '555',\n",
       " '556',\n",
       " '557',\n",
       " '558',\n",
       " '559',\n",
       " '560',\n",
       " '561',\n",
       " '562',\n",
       " '563',\n",
       " '564',\n",
       " '565',\n",
       " '566',\n",
       " '567',\n",
       " '568',\n",
       " '569',\n",
       " '570',\n",
       " '571',\n",
       " '572',\n",
       " '573',\n",
       " '574',\n",
       " '575',\n",
       " '576',\n",
       " '577',\n",
       " '578',\n",
       " '579',\n",
       " '580',\n",
       " '581',\n",
       " '582',\n",
       " '583',\n",
       " '584',\n",
       " '585',\n",
       " '586',\n",
       " '587',\n",
       " '588',\n",
       " '589',\n",
       " '590',\n",
       " '591',\n",
       " '592',\n",
       " '593',\n",
       " '594',\n",
       " '595',\n",
       " '596',\n",
       " '597',\n",
       " '598',\n",
       " '599',\n",
       " '600',\n",
       " '601',\n",
       " '602',\n",
       " '603',\n",
       " '604',\n",
       " '605',\n",
       " '606',\n",
       " '607',\n",
       " '608',\n",
       " '609',\n",
       " '610',\n",
       " '611',\n",
       " '612',\n",
       " '613',\n",
       " '614',\n",
       " '615',\n",
       " '616',\n",
       " '617',\n",
       " '618',\n",
       " '619',\n",
       " '620',\n",
       " '621',\n",
       " '622',\n",
       " '623',\n",
       " '624',\n",
       " '625',\n",
       " '626',\n",
       " '627',\n",
       " '628',\n",
       " '629',\n",
       " '630',\n",
       " '631',\n",
       " '632',\n",
       " '633',\n",
       " '634',\n",
       " '635',\n",
       " '636',\n",
       " '637',\n",
       " '638',\n",
       " '639',\n",
       " '640',\n",
       " '641',\n",
       " '642',\n",
       " '643',\n",
       " '644',\n",
       " '645',\n",
       " '646',\n",
       " '647',\n",
       " '648',\n",
       " '649',\n",
       " '650',\n",
       " '651',\n",
       " '652',\n",
       " '653',\n",
       " '654',\n",
       " '655',\n",
       " '656',\n",
       " '657',\n",
       " '658',\n",
       " '659',\n",
       " '660',\n",
       " '661',\n",
       " '662',\n",
       " '663',\n",
       " '664',\n",
       " '665',\n",
       " '666',\n",
       " '667',\n",
       " '668',\n",
       " '669',\n",
       " '670',\n",
       " '671',\n",
       " '672',\n",
       " '673',\n",
       " '674',\n",
       " '675',\n",
       " '676',\n",
       " '677',\n",
       " '678',\n",
       " '679',\n",
       " '680',\n",
       " '681',\n",
       " '682',\n",
       " '683',\n",
       " '684',\n",
       " '685',\n",
       " '686',\n",
       " '687',\n",
       " '688',\n",
       " '689',\n",
       " '690',\n",
       " '691',\n",
       " '692',\n",
       " '693',\n",
       " '694',\n",
       " '695',\n",
       " '696',\n",
       " '697',\n",
       " '698',\n",
       " '699',\n",
       " '700',\n",
       " '701',\n",
       " '702',\n",
       " '703',\n",
       " '704',\n",
       " '705',\n",
       " '706',\n",
       " '707',\n",
       " '708',\n",
       " '709',\n",
       " '710',\n",
       " '711',\n",
       " '712',\n",
       " '713',\n",
       " '714',\n",
       " '715',\n",
       " '716',\n",
       " '717',\n",
       " '718',\n",
       " '719',\n",
       " '720',\n",
       " '721',\n",
       " '722',\n",
       " '723',\n",
       " '724',\n",
       " '725',\n",
       " '726',\n",
       " '727',\n",
       " '728',\n",
       " '729',\n",
       " '730',\n",
       " '731',\n",
       " '732',\n",
       " '733',\n",
       " '734',\n",
       " '735',\n",
       " '736',\n",
       " '737',\n",
       " '738',\n",
       " '739',\n",
       " '740',\n",
       " '741',\n",
       " '742',\n",
       " '743',\n",
       " '744',\n",
       " '745',\n",
       " '746',\n",
       " '747',\n",
       " '748',\n",
       " '749',\n",
       " '750',\n",
       " '751',\n",
       " '752',\n",
       " '753',\n",
       " '754',\n",
       " '755',\n",
       " '756',\n",
       " '757',\n",
       " '758',\n",
       " '759',\n",
       " '760',\n",
       " '761',\n",
       " '762',\n",
       " '763',\n",
       " '764',\n",
       " '765',\n",
       " '766',\n",
       " '767',\n",
       " '768',\n",
       " '769',\n",
       " '770',\n",
       " '771',\n",
       " '772',\n",
       " '773',\n",
       " '774',\n",
       " '775',\n",
       " '776',\n",
       " '777',\n",
       " '778',\n",
       " '779',\n",
       " '780',\n",
       " '781',\n",
       " '782',\n",
       " '783',\n",
       " '784',\n",
       " '785',\n",
       " '786',\n",
       " '787',\n",
       " '788',\n",
       " '789',\n",
       " '790',\n",
       " '791',\n",
       " '792',\n",
       " '793',\n",
       " '794',\n",
       " '795',\n",
       " '796',\n",
       " '797',\n",
       " '798',\n",
       " '799',\n",
       " '800',\n",
       " '801',\n",
       " '802',\n",
       " '803',\n",
       " '804',\n",
       " '805',\n",
       " '806',\n",
       " '807',\n",
       " '808',\n",
       " '809',\n",
       " '810',\n",
       " '811',\n",
       " '812',\n",
       " '813',\n",
       " '814',\n",
       " '815',\n",
       " '816',\n",
       " '817',\n",
       " '818',\n",
       " '819',\n",
       " '820',\n",
       " '821',\n",
       " '822',\n",
       " '823',\n",
       " '824',\n",
       " '825',\n",
       " '826',\n",
       " '827',\n",
       " '828',\n",
       " '829',\n",
       " '830',\n",
       " '831',\n",
       " '832',\n",
       " '833',\n",
       " '834',\n",
       " '835',\n",
       " '836',\n",
       " '837',\n",
       " '838',\n",
       " '839',\n",
       " '840',\n",
       " '841',\n",
       " '842',\n",
       " '843',\n",
       " '844',\n",
       " '845',\n",
       " '846',\n",
       " '847',\n",
       " '848',\n",
       " '849',\n",
       " '850',\n",
       " '851',\n",
       " '852',\n",
       " '853',\n",
       " '854',\n",
       " '855',\n",
       " '856',\n",
       " '857',\n",
       " '858',\n",
       " '859',\n",
       " '860',\n",
       " '861',\n",
       " '862',\n",
       " '863',\n",
       " '864',\n",
       " '865',\n",
       " '866',\n",
       " '867',\n",
       " '868',\n",
       " '869',\n",
       " '870',\n",
       " '871',\n",
       " '872',\n",
       " '873',\n",
       " '874',\n",
       " '875',\n",
       " '876',\n",
       " '877',\n",
       " '878',\n",
       " '879',\n",
       " '880',\n",
       " '881',\n",
       " '882',\n",
       " '883',\n",
       " '884',\n",
       " '885',\n",
       " '886',\n",
       " '887',\n",
       " '888',\n",
       " '889',\n",
       " '890',\n",
       " '891',\n",
       " '892',\n",
       " '893',\n",
       " '894',\n",
       " '895',\n",
       " '896',\n",
       " '897',\n",
       " '898',\n",
       " '899',\n",
       " '900',\n",
       " '901',\n",
       " '902',\n",
       " '903',\n",
       " '904',\n",
       " '905',\n",
       " '906',\n",
       " '907',\n",
       " '908',\n",
       " '909',\n",
       " '910',\n",
       " '911',\n",
       " '912',\n",
       " '913',\n",
       " '914',\n",
       " '915',\n",
       " '916',\n",
       " '917',\n",
       " '918',\n",
       " '919',\n",
       " '920',\n",
       " '921',\n",
       " '922',\n",
       " '923',\n",
       " '924',\n",
       " '925',\n",
       " '926',\n",
       " '927',\n",
       " '928',\n",
       " '929',\n",
       " '930',\n",
       " '931',\n",
       " '932',\n",
       " '933',\n",
       " '934',\n",
       " '935',\n",
       " '936',\n",
       " '937',\n",
       " '938',\n",
       " '939',\n",
       " '940',\n",
       " '941',\n",
       " '942',\n",
       " '943',\n",
       " '944',\n",
       " '945',\n",
       " '946',\n",
       " '947',\n",
       " '948',\n",
       " '949',\n",
       " '950',\n",
       " '951',\n",
       " '952',\n",
       " '953',\n",
       " '954',\n",
       " '955',\n",
       " '956',\n",
       " '957',\n",
       " '958',\n",
       " '959',\n",
       " '960',\n",
       " '961',\n",
       " '962',\n",
       " '963',\n",
       " '964',\n",
       " '965',\n",
       " '966',\n",
       " '967',\n",
       " '968',\n",
       " '969',\n",
       " '970',\n",
       " '971',\n",
       " '972',\n",
       " '973',\n",
       " '974',\n",
       " '975',\n",
       " '976',\n",
       " '977',\n",
       " '978',\n",
       " '979',\n",
       " '980',\n",
       " '981',\n",
       " '982',\n",
       " '983',\n",
       " '984',\n",
       " '985',\n",
       " '986',\n",
       " '987',\n",
       " '988',\n",
       " '989',\n",
       " '990',\n",
       " '991',\n",
       " '992',\n",
       " '993',\n",
       " '994',\n",
       " '995',\n",
       " '996',\n",
       " '997',\n",
       " '998',\n",
       " '999']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_mimic_data_train_set_with_specified_M_and_R(num_of_movies, num_of_rates):\n",
    "    num_of_users = num_of_rates / num_of_movies\n",
    "    train = {}\n",
    "    history = [str(x) for x in range(num_of_movies)]\n",
    "    for x in xrange(num_of_users):\n",
    "        train[x] = history[:]\n",
    "        \n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-02 08:14:48,154 : INFO : collecting all words and their counts\n",
      "2017-04-02 08:14:48,154 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-04-02 08:14:48,215 : INFO : collected 10 word types from a corpus of 1000000 raw words and 1000 sentences\n",
      "2017-04-02 08:14:48,215 : INFO : Loading a fresh vocabulary\n",
      "2017-04-02 08:14:48,216 : INFO : min_count=1 retains 10 unique words (100% of original 10, drops 0)\n",
      "2017-04-02 08:14:48,216 : INFO : min_count=1 leaves 1000000 word corpus (100% of original 1000000, drops 0)\n",
      "2017-04-02 08:14:48,217 : INFO : deleting the raw counts dictionary of 10 items\n",
      "2017-04-02 08:14:48,217 : INFO : sample=0.001 downsamples 9 most-common words\n",
      "2017-04-02 08:14:48,218 : INFO : downsampling leaves estimated 104820 word corpus (10.5% of prior 1000000)\n",
      "2017-04-02 08:14:48,218 : INFO : estimated required memory for 10 words and 100 dimensions: 13000 bytes\n",
      "2017-04-02 08:14:48,218 : INFO : resetting layer weights\n",
      "2017-04-02 08:14:48,219 : INFO : training model with 3 workers on 10 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=1\n",
      "2017-04-02 08:14:48,219 : INFO : expecting 1000 sentences, matching count from corpus used for vocabulary survey\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start preparing training set.\n",
      "preparing training set done.\n",
      "len(train): 1000\n",
      "currently, num_of_movies=1000, num_of_rates=1000000.\n",
      "start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-02 08:14:49,222 : INFO : PROGRESS: at 18.55% examples, 389496 words/s, in_qsize 5, out_qsize 3\n",
      "2017-04-02 08:14:50,222 : INFO : PROGRESS: at 40.24% examples, 421748 words/s, in_qsize 3, out_qsize 3\n",
      "2017-04-02 08:14:51,222 : INFO : PROGRESS: at 59.77% examples, 417665 words/s, in_qsize 4, out_qsize 4\n",
      "2017-04-02 08:14:52,222 : INFO : PROGRESS: at 78.20% examples, 409840 words/s, in_qsize 2, out_qsize 1\n",
      "2017-04-02 08:14:53,222 : INFO : PROGRESS: at 99.35% examples, 416511 words/s, in_qsize 6, out_qsize 2\n",
      "2017-04-02 08:14:53,249 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-02 08:14:53,249 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-02 08:14:53,250 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-02 08:14:53,251 : INFO : training on 20000000 raw words (2096579 effective words) took 5.0s, 416823 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training finished\n",
      "start modeling\n",
      "modeling finished\n",
      "interval: 5.21404\n",
      "start preparing training set.\n",
      "preparing training set done.\n",
      "len(train): "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-02 08:14:53,520 : INFO : collecting all words and their counts\n",
      "2017-04-02 08:14:53,520 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-04-02 08:14:53,640 : INFO : collected 10 word types from a corpus of 2000000 raw words and 2000 sentences\n",
      "2017-04-02 08:14:53,641 : INFO : Loading a fresh vocabulary\n",
      "2017-04-02 08:14:53,641 : INFO : min_count=1 retains 10 unique words (100% of original 10, drops 0)\n",
      "2017-04-02 08:14:53,641 : INFO : min_count=1 leaves 2000000 word corpus (100% of original 2000000, drops 0)\n",
      "2017-04-02 08:14:53,642 : INFO : deleting the raw counts dictionary of 10 items\n",
      "2017-04-02 08:14:53,642 : INFO : sample=0.001 downsamples 9 most-common words\n",
      "2017-04-02 08:14:53,643 : INFO : downsampling leaves estimated 209641 word corpus (10.5% of prior 2000000)\n",
      "2017-04-02 08:14:53,643 : INFO : estimated required memory for 10 words and 100 dimensions: 13000 bytes\n",
      "2017-04-02 08:14:53,644 : INFO : resetting layer weights\n",
      "2017-04-02 08:14:53,644 : INFO : training model with 3 workers on 10 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=1\n",
      "2017-04-02 08:14:53,644 : INFO : expecting 2000 sentences, matching count from corpus used for vocabulary survey\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "currently, num_of_movies=1000, num_of_rates=2000000.\n",
      "start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-02 08:14:54,646 : INFO : PROGRESS: at 9.48% examples, 398012 words/s, in_qsize 2, out_qsize 3\n",
      "2017-04-02 08:14:55,646 : INFO : PROGRESS: at 18.74% examples, 392937 words/s, in_qsize 1, out_qsize 1\n",
      "2017-04-02 08:14:56,647 : INFO : PROGRESS: at 27.86% examples, 389329 words/s, in_qsize 3, out_qsize 2\n",
      "2017-04-02 08:14:57,647 : INFO : PROGRESS: at 36.90% examples, 386790 words/s, in_qsize 3, out_qsize 4\n",
      "2017-04-02 08:14:58,647 : INFO : PROGRESS: at 45.95% examples, 385198 words/s, in_qsize 4, out_qsize 1\n",
      "2017-04-02 08:14:59,647 : INFO : PROGRESS: at 55.15% examples, 385151 words/s, in_qsize 6, out_qsize 2\n",
      "2017-04-02 08:15:00,648 : INFO : PROGRESS: at 64.11% examples, 383813 words/s, in_qsize 4, out_qsize 2\n",
      "2017-04-02 08:15:01,647 : INFO : PROGRESS: at 73.39% examples, 384341 words/s, in_qsize 2, out_qsize 2\n",
      "2017-04-02 08:15:02,648 : INFO : PROGRESS: at 82.80% examples, 385413 words/s, in_qsize 3, out_qsize 2\n",
      "2017-04-02 08:15:03,648 : INFO : PROGRESS: at 92.06% examples, 385638 words/s, in_qsize 5, out_qsize 2\n",
      "2017-04-02 08:15:04,500 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-02 08:15:04,501 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-02 08:15:04,501 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-02 08:15:04,502 : INFO : training on 40000000 raw words (4189974 effective words) took 10.9s, 385922 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training finished\n",
      "start modeling\n",
      "modeling finished\n",
      "interval: 11.2231\n",
      "start preparing training set.\n",
      "preparing training set done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-02 08:15:04,889 : INFO : collecting all words and their counts\n",
      "2017-04-02 08:15:04,889 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-04-02 08:15:05,066 : INFO : collected 10 word types from a corpus of 3000000 raw words and 3000 sentences\n",
      "2017-04-02 08:15:05,067 : INFO : Loading a fresh vocabulary\n",
      "2017-04-02 08:15:05,067 : INFO : min_count=1 retains 10 unique words (100% of original 10, drops 0)\n",
      "2017-04-02 08:15:05,068 : INFO : min_count=1 leaves 3000000 word corpus (100% of original 3000000, drops 0)\n",
      "2017-04-02 08:15:05,068 : INFO : deleting the raw counts dictionary of 10 items\n",
      "2017-04-02 08:15:05,069 : INFO : sample=0.001 downsamples 9 most-common words\n",
      "2017-04-02 08:15:05,069 : INFO : downsampling leaves estimated 314462 word corpus (10.5% of prior 3000000)\n",
      "2017-04-02 08:15:05,070 : INFO : estimated required memory for 10 words and 100 dimensions: 13000 bytes\n",
      "2017-04-02 08:15:05,070 : INFO : resetting layer weights\n",
      "2017-04-02 08:15:05,071 : INFO : training model with 3 workers on 10 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=1\n",
      "2017-04-02 08:15:05,071 : INFO : expecting 3000 sentences, matching count from corpus used for vocabulary survey\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train): 3000\n",
      "currently, num_of_movies=1000, num_of_rates=3000000.\n",
      "start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-02 08:15:06,073 : INFO : PROGRESS: at 6.21% examples, 391061 words/s, in_qsize 4, out_qsize 4\n",
      "2017-04-02 08:15:07,074 : INFO : PROGRESS: at 12.37% examples, 388931 words/s, in_qsize 3, out_qsize 1\n",
      "2017-04-02 08:15:08,074 : INFO : PROGRESS: at 18.55% examples, 388893 words/s, in_qsize 6, out_qsize 3\n",
      "2017-04-02 08:15:09,074 : INFO : PROGRESS: at 24.64% examples, 387446 words/s, in_qsize 1, out_qsize 2\n",
      "2017-04-02 08:15:10,074 : INFO : PROGRESS: at 30.63% examples, 385159 words/s, in_qsize 6, out_qsize 2\n",
      "2017-04-02 08:15:11,075 : INFO : PROGRESS: at 36.63% examples, 383758 words/s, in_qsize 3, out_qsize 4\n",
      "2017-04-02 08:15:12,075 : INFO : PROGRESS: at 42.69% examples, 383310 words/s, in_qsize 4, out_qsize 3\n",
      "2017-04-02 08:15:13,076 : INFO : PROGRESS: at 48.94% examples, 384366 words/s, in_qsize 4, out_qsize 2\n",
      "2017-04-02 08:15:14,076 : INFO : PROGRESS: at 55.12% examples, 384831 words/s, in_qsize 1, out_qsize 1\n",
      "2017-04-02 08:15:15,077 : INFO : PROGRESS: at 61.31% examples, 385136 words/s, in_qsize 2, out_qsize 2\n",
      "2017-04-02 08:15:16,077 : INFO : PROGRESS: at 67.37% examples, 384752 words/s, in_qsize 3, out_qsize 2\n",
      "2017-04-02 08:15:17,077 : INFO : PROGRESS: at 73.46% examples, 384588 words/s, in_qsize 6, out_qsize 3\n",
      "2017-04-02 08:15:18,078 : INFO : PROGRESS: at 79.47% examples, 384024 words/s, in_qsize 5, out_qsize 2\n",
      "2017-04-02 08:15:19,078 : INFO : PROGRESS: at 85.46% examples, 383565 words/s, in_qsize 2, out_qsize 2\n",
      "2017-04-02 08:15:20,078 : INFO : PROGRESS: at 91.52% examples, 383398 words/s, in_qsize 4, out_qsize 4\n",
      "2017-04-02 08:15:21,078 : INFO : PROGRESS: at 97.64% examples, 383483 words/s, in_qsize 4, out_qsize 3\n",
      "2017-04-02 08:15:21,471 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-02 08:15:21,472 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-02 08:15:21,473 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-02 08:15:21,476 : INFO : training on 60000000 raw words (6286572 effective words) took 16.4s, 383238 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training finished\n",
      "start modeling\n",
      "modeling finished\n",
      "interval: 16.9487\n",
      "start preparing training set.\n",
      "preparing training set done.\n",
      "len(train): 4000\n",
      "currently, num_of_movies=1000, num_of_rates=4000000.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-02 08:15:21,969 : INFO : collecting all words and their counts\n",
      "2017-04-02 08:15:21,969 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-02 08:15:22,209 : INFO : collected 10 word types from a corpus of 4000000 raw words and 4000 sentences\n",
      "2017-04-02 08:15:22,210 : INFO : Loading a fresh vocabulary\n",
      "2017-04-02 08:15:22,210 : INFO : min_count=1 retains 10 unique words (100% of original 10, drops 0)\n",
      "2017-04-02 08:15:22,210 : INFO : min_count=1 leaves 4000000 word corpus (100% of original 4000000, drops 0)\n",
      "2017-04-02 08:15:22,211 : INFO : deleting the raw counts dictionary of 10 items\n",
      "2017-04-02 08:15:22,211 : INFO : sample=0.001 downsamples 9 most-common words\n",
      "2017-04-02 08:15:22,212 : INFO : downsampling leaves estimated 419283 word corpus (10.5% of prior 4000000)\n",
      "2017-04-02 08:15:22,212 : INFO : estimated required memory for 10 words and 100 dimensions: 13000 bytes\n",
      "2017-04-02 08:15:22,213 : INFO : resetting layer weights\n",
      "2017-04-02 08:15:22,214 : INFO : training model with 3 workers on 10 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=1\n",
      "2017-04-02 08:15:22,214 : INFO : expecting 4000 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-02 08:15:23,216 : INFO : PROGRESS: at 4.68% examples, 392729 words/s, in_qsize 1, out_qsize 1\n",
      "2017-04-02 08:15:24,216 : INFO : PROGRESS: at 9.38% examples, 393609 words/s, in_qsize 4, out_qsize 1\n",
      "2017-04-02 08:15:25,216 : INFO : PROGRESS: at 14.12% examples, 394734 words/s, in_qsize 4, out_qsize 1\n",
      "2017-04-02 08:15:26,216 : INFO : PROGRESS: at 18.76% examples, 393433 words/s, in_qsize 3, out_qsize 3\n",
      "2017-04-02 08:15:27,217 : INFO : PROGRESS: at 23.36% examples, 391743 words/s, in_qsize 2, out_qsize 3\n",
      "2017-04-02 08:15:28,217 : INFO : PROGRESS: at 27.90% examples, 389737 words/s, in_qsize 1, out_qsize 3\n",
      "2017-04-02 08:15:29,218 : INFO : PROGRESS: at 32.55% examples, 389756 words/s, in_qsize 2, out_qsize 2\n",
      "2017-04-02 08:15:30,218 : INFO : PROGRESS: at 37.16% examples, 389178 words/s, in_qsize 4, out_qsize 3\n",
      "2017-04-02 08:15:31,218 : INFO : PROGRESS: at 41.67% examples, 387988 words/s, in_qsize 2, out_qsize 4\n",
      "2017-04-02 08:15:32,218 : INFO : PROGRESS: at 46.24% examples, 387403 words/s, in_qsize 4, out_qsize 1\n",
      "2017-04-02 08:15:33,219 : INFO : PROGRESS: at 50.95% examples, 388082 words/s, in_qsize 4, out_qsize 3\n",
      "2017-04-02 08:15:34,219 : INFO : PROGRESS: at 55.58% examples, 388056 words/s, in_qsize 6, out_qsize 4\n",
      "2017-04-02 08:15:35,219 : INFO : PROGRESS: at 60.21% examples, 388047 words/s, in_qsize 2, out_qsize 2\n",
      "2017-04-02 08:15:36,219 : INFO : PROGRESS: at 64.83% examples, 388032 words/s, in_qsize 3, out_qsize 2\n",
      "2017-04-02 08:15:37,220 : INFO : PROGRESS: at 69.57% examples, 388669 words/s, in_qsize 4, out_qsize 2\n",
      "2017-04-02 08:15:38,220 : INFO : PROGRESS: at 74.16% examples, 388411 words/s, in_qsize 6, out_qsize 2\n",
      "2017-04-02 08:15:39,220 : INFO : PROGRESS: at 78.77% examples, 388284 words/s, in_qsize 6, out_qsize 2\n",
      "2017-04-02 08:15:40,221 : INFO : PROGRESS: at 83.44% examples, 388489 words/s, in_qsize 5, out_qsize 3\n",
      "2017-04-02 08:15:41,222 : INFO : PROGRESS: at 88.12% examples, 388699 words/s, in_qsize 6, out_qsize 2\n",
      "2017-04-02 08:15:42,222 : INFO : PROGRESS: at 92.77% examples, 388788 words/s, in_qsize 5, out_qsize 1\n",
      "2017-04-02 08:15:43,222 : INFO : PROGRESS: at 97.39% examples, 388744 words/s, in_qsize 5, out_qsize 3\n",
      "2017-04-02 08:15:43,773 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-02 08:15:43,774 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-02 08:15:43,775 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-02 08:15:43,775 : INFO : training on 80000000 raw words (8384259 effective words) took 21.6s, 388880 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training finished\n",
      "start modeling\n",
      "modeling finished\n",
      "interval: 22.2581\n",
      "start preparing training set.\n",
      "preparing training set done.\n",
      "len(train): 5000\n",
      "currently, num_of_movies=1000, num_of_rates=5000000."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-02 08:15:44,385 : INFO : collecting all words and their counts\n",
      "2017-04-02 08:15:44,386 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-02 08:15:44,687 : INFO : collected 10 word types from a corpus of 5000000 raw words and 5000 sentences\n",
      "2017-04-02 08:15:44,687 : INFO : Loading a fresh vocabulary\n",
      "2017-04-02 08:15:44,688 : INFO : min_count=1 retains 10 unique words (100% of original 10, drops 0)\n",
      "2017-04-02 08:15:44,688 : INFO : min_count=1 leaves 5000000 word corpus (100% of original 5000000, drops 0)\n",
      "2017-04-02 08:15:44,689 : INFO : deleting the raw counts dictionary of 10 items\n",
      "2017-04-02 08:15:44,689 : INFO : sample=0.001 downsamples 9 most-common words\n",
      "2017-04-02 08:15:44,689 : INFO : downsampling leaves estimated 524104 word corpus (10.5% of prior 5000000)\n",
      "2017-04-02 08:15:44,690 : INFO : estimated required memory for 10 words and 100 dimensions: 13000 bytes\n",
      "2017-04-02 08:15:44,691 : INFO : resetting layer weights\n",
      "2017-04-02 08:15:44,692 : INFO : training model with 3 workers on 10 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=1\n",
      "2017-04-02 08:15:44,692 : INFO : expecting 5000 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-02 08:15:45,694 : INFO : PROGRESS: at 3.74% examples, 392851 words/s, in_qsize 1, out_qsize 1\n",
      "2017-04-02 08:15:46,694 : INFO : PROGRESS: at 7.43% examples, 389797 words/s, in_qsize 3, out_qsize 0\n",
      "2017-04-02 08:15:47,694 : INFO : PROGRESS: at 11.15% examples, 389682 words/s, in_qsize 6, out_qsize 4\n",
      "2017-04-02 08:15:48,695 : INFO : PROGRESS: at 14.78% examples, 387279 words/s, in_qsize 1, out_qsize 3\n",
      "2017-04-02 08:15:49,695 : INFO : PROGRESS: at 18.51% examples, 387879 words/s, in_qsize 6, out_qsize 0\n",
      "2017-04-02 08:15:50,695 : INFO : PROGRESS: at 22.18% examples, 387323 words/s, in_qsize 5, out_qsize 4\n",
      "2017-04-02 08:15:51,695 : INFO : PROGRESS: at 25.88% examples, 387301 words/s, in_qsize 2, out_qsize 1\n",
      "2017-04-02 08:15:52,696 : INFO : PROGRESS: at 29.56% examples, 386998 words/s, in_qsize 1, out_qsize 3\n",
      "2017-04-02 08:15:53,696 : INFO : PROGRESS: at 33.22% examples, 386569 words/s, in_qsize 4, out_qsize 2\n",
      "2017-04-02 08:15:54,697 : INFO : PROGRESS: at 36.88% examples, 386176 words/s, in_qsize 4, out_qsize 3\n",
      "2017-04-02 08:15:55,697 : INFO : PROGRESS: at 40.62% examples, 386688 words/s, in_qsize 1, out_qsize 5\n",
      "2017-04-02 08:15:56,698 : INFO : PROGRESS: at 44.32% examples, 386765 words/s, in_qsize 0, out_qsize 4\n",
      "2017-04-02 08:15:57,698 : INFO : PROGRESS: at 48.02% examples, 386811 words/s, in_qsize 3, out_qsize 2\n",
      "2017-04-02 08:15:58,698 : INFO : PROGRESS: at 51.67% examples, 386561 words/s, in_qsize 2, out_qsize 1\n",
      "2017-04-02 08:15:59,698 : INFO : PROGRESS: at 55.40% examples, 386847 words/s, in_qsize 6, out_qsize 3\n",
      "2017-04-02 08:16:00,698 : INFO : PROGRESS: at 59.10% examples, 386933 words/s, in_qsize 5, out_qsize 2\n",
      "2017-04-02 08:16:01,699 : INFO : PROGRESS: at 62.76% examples, 386700 words/s, in_qsize 3, out_qsize 2\n",
      "2017-04-02 08:16:02,699 : INFO : PROGRESS: at 66.39% examples, 386389 words/s, in_qsize 2, out_qsize 1\n",
      "2017-04-02 08:16:03,699 : INFO : PROGRESS: at 70.19% examples, 387010 words/s, in_qsize 3, out_qsize 2\n",
      "2017-04-02 08:16:04,700 : INFO : PROGRESS: at 73.77% examples, 386442 words/s, in_qsize 0, out_qsize 0\n",
      "2017-04-02 08:16:05,700 : INFO : PROGRESS: at 77.47% examples, 386546 words/s, in_qsize 5, out_qsize 3\n",
      "2017-04-02 08:16:06,700 : INFO : PROGRESS: at 81.12% examples, 386324 words/s, in_qsize 3, out_qsize 3\n",
      "2017-04-02 08:16:07,700 : INFO : PROGRESS: at 85.05% examples, 387406 words/s, in_qsize 5, out_qsize 2\n",
      "2017-04-02 08:16:08,701 : INFO : PROGRESS: at 89.45% examples, 390516 words/s, in_qsize 3, out_qsize 3\n",
      "2017-04-02 08:16:09,701 : INFO : PROGRESS: at 93.25% examples, 390804 words/s, in_qsize 0, out_qsize 3\n",
      "2017-04-02 08:16:10,701 : INFO : PROGRESS: at 96.98% examples, 390874 words/s, in_qsize 6, out_qsize 2\n",
      "2017-04-02 08:16:11,491 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-02 08:16:11,492 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-02 08:16:11,493 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-02 08:16:11,496 : INFO : training on 100000000 raw words (10482482 effective words) took 26.8s, 391092 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training finished\n",
      "start modeling\n",
      "modeling finished\n",
      "interval: 27.6678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-02 08:16:12,363 : INFO : collecting all words and their counts\n",
      "2017-04-02 08:16:12,363 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start preparing training set.\n",
      "preparing training set done.\n",
      "len(train): 6000\n",
      "currently, num_of_movies=1000, num_of_rates=6000000.\n",
      "start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-04-02 08:16:12,720 : INFO : collected 10 word types from a corpus of 6000000 raw words and 6000 sentences\n",
      "2017-04-02 08:16:12,721 : INFO : Loading a fresh vocabulary\n",
      "2017-04-02 08:16:12,721 : INFO : min_count=1 retains 10 unique words (100% of original 10, drops 0)\n",
      "2017-04-02 08:16:12,722 : INFO : min_count=1 leaves 6000000 word corpus (100% of original 6000000, drops 0)\n",
      "2017-04-02 08:16:12,723 : INFO : deleting the raw counts dictionary of 10 items\n",
      "2017-04-02 08:16:12,723 : INFO : sample=0.001 downsamples 9 most-common words\n",
      "2017-04-02 08:16:12,724 : INFO : downsampling leaves estimated 628925 word corpus (10.5% of prior 6000000)\n",
      "2017-04-02 08:16:12,724 : INFO : estimated required memory for 10 words and 100 dimensions: 13000 bytes\n",
      "2017-04-02 08:16:12,725 : INFO : resetting layer weights\n",
      "2017-04-02 08:16:12,725 : INFO : training model with 3 workers on 10 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=1\n",
      "2017-04-02 08:16:12,726 : INFO : expecting 6000 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-04-02 08:16:13,728 : INFO : PROGRESS: at 3.13% examples, 394518 words/s, in_qsize 2, out_qsize 3\n",
      "2017-04-02 08:16:14,728 : INFO : PROGRESS: at 6.40% examples, 402598 words/s, in_qsize 6, out_qsize 3\n",
      "2017-04-02 08:16:15,728 : INFO : PROGRESS: at 9.51% examples, 398569 words/s, in_qsize 3, out_qsize 1\n",
      "2017-04-02 08:16:16,728 : INFO : PROGRESS: at 12.55% examples, 394638 words/s, in_qsize 4, out_qsize 1\n",
      "2017-04-02 08:16:17,729 : INFO : PROGRESS: at 15.66% examples, 393831 words/s, in_qsize 4, out_qsize 2\n",
      "2017-04-02 08:16:18,729 : INFO : PROGRESS: at 18.85% examples, 394926 words/s, in_qsize 0, out_qsize 3\n",
      "2017-04-02 08:16:19,730 : INFO : PROGRESS: at 21.98% examples, 394676 words/s, in_qsize 2, out_qsize 4\n",
      "2017-04-02 08:16:20,730 : INFO : PROGRESS: at 25.74% examples, 404364 words/s, in_qsize 3, out_qsize 1\n",
      "2017-04-02 08:16:21,731 : INFO : PROGRESS: at 29.56% examples, 412721 words/s, in_qsize 6, out_qsize 1\n",
      "2017-04-02 08:16:22,730 : INFO : PROGRESS: at 32.95% examples, 413962 words/s, in_qsize 2, out_qsize 0\n",
      "2017-04-02 08:16:23,731 : INFO : PROGRESS: at 36.30% examples, 414605 words/s, in_qsize 6, out_qsize 3\n",
      "2017-04-02 08:16:24,731 : INFO : PROGRESS: at 39.58% examples, 414431 words/s, in_qsize 3, out_qsize 3\n",
      "2017-04-02 08:16:25,732 : INFO : PROGRESS: at 42.66% examples, 412393 words/s, in_qsize 2, out_qsize 3\n",
      "2017-04-02 08:16:26,733 : INFO : PROGRESS: at 45.74% examples, 410625 words/s, in_qsize 5, out_qsize 5\n",
      "2017-04-02 08:16:27,733 : INFO : PROGRESS: at 48.87% examples, 409459 words/s, in_qsize 6, out_qsize 2\n",
      "2017-04-02 08:16:28,733 : INFO : PROGRESS: at 52.06% examples, 408997 words/s, in_qsize 0, out_qsize 2\n",
      "2017-04-02 08:16:29,733 : INFO : PROGRESS: at 55.11% examples, 407450 words/s, in_qsize 6, out_qsize 3\n",
      "2017-04-02 08:16:30,733 : INFO : PROGRESS: at 58.20% examples, 406440 words/s, in_qsize 4, out_qsize 2\n",
      "2017-04-02 08:16:31,733 : INFO : PROGRESS: at 61.32% examples, 405729 words/s, in_qsize 6, out_qsize 2\n",
      "2017-04-02 08:16:32,734 : INFO : PROGRESS: at 64.37% examples, 404629 words/s, in_qsize 2, out_qsize 1\n",
      "2017-04-02 08:16:33,734 : INFO : PROGRESS: at 67.48% examples, 403946 words/s, in_qsize 4, out_qsize 3\n",
      "2017-04-02 08:16:34,734 : INFO : PROGRESS: at 70.55% examples, 403096 words/s, in_qsize 4, out_qsize 2\n",
      "2017-04-02 08:16:35,734 : INFO : PROGRESS: at 73.65% examples, 402601 words/s, in_qsize 5, out_qsize 2\n",
      "2017-04-02 08:16:36,734 : INFO : PROGRESS: at 76.73% examples, 401941 words/s, in_qsize 1, out_qsize 2\n",
      "2017-04-02 08:16:37,735 : INFO : PROGRESS: at 79.82% examples, 401441 words/s, in_qsize 0, out_qsize 1\n",
      "2017-04-02 08:16:38,735 : INFO : PROGRESS: at 82.88% examples, 400831 words/s, in_qsize 6, out_qsize 2\n",
      "2017-04-02 08:16:39,735 : INFO : PROGRESS: at 85.96% examples, 400345 words/s, in_qsize 1, out_qsize 4\n",
      "2017-04-02 08:16:40,736 : INFO : PROGRESS: at 89.07% examples, 399988 words/s, in_qsize 3, out_qsize 6\n",
      "2017-04-02 08:16:41,736 : INFO : PROGRESS: at 92.19% examples, 399720 words/s, in_qsize 2, out_qsize 3\n",
      "2017-04-02 08:16:42,736 : INFO : PROGRESS: at 95.37% examples, 399717 words/s, in_qsize 5, out_qsize 2\n",
      "2017-04-02 08:16:43,736 : INFO : PROGRESS: at 98.71% examples, 400430 words/s, in_qsize 5, out_qsize 1\n",
      "2017-04-02 08:16:44,141 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-04-02 08:16:44,142 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-04-02 08:16:44,142 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-04-02 08:16:44,143 : INFO : training on 120000000 raw words (12578909 effective words) took 31.4s, 400396 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training finished\n",
      "start modeling\n",
      "modeling finished\n",
      "interval: 32.5915\n",
      "(1000, 1000000, 5.214035987854004)\n",
      "(1000, 2000000, 11.223101139068604)\n",
      "(1000, 3000000, 16.948730945587158)\n",
      "(1000, 4000000, 22.258097887039185)\n",
      "(1000, 5000000, 27.667788982391357)\n",
      "(1000, 6000000, 32.591460943222046)\n"
     ]
    }
   ],
   "source": [
    "#train_set_size_list = 10 ** np.array(range(1, 4 + 1))\n",
    "#train_set_size_list = 10**4 * np.array(range(1, 5 + 1))\n",
    "#iter_list = [20, 30, 40]\n",
    "\n",
    "#num_of_movies = None #1000\n",
    "#num_of_rates = 10 * 10000\n",
    "\n",
    "#num_of_movies_list = [1000, 3000, 5000]\n",
    "num_of_movies_list = [1000]\n",
    "num_of_rates_list = 10**6 * np.array(range(1, 6 + 1))\n",
    "\n",
    "metric = []\n",
    "\n",
    "###\n",
    "\n",
    "test_data_inner_ratio = 0.5  # insignificant in this notebook\n",
    "s, mc, w = 100, 1, 1         # insignificant in this notebook\n",
    "batch_words = 1          # insignificant in this notebook\n",
    "para_iter = 20\n",
    "\n",
    "seed = 2 \n",
    "\n",
    "for __i, num_of_movies in enumerate(num_of_movies_list):\n",
    "    for __j, num_of_rates in enumerate(num_of_rates_list):\n",
    "        random.seed(seed)\n",
    "        \n",
    "        print 'start preparing training set.'\n",
    "        #train = extract_data_from_file_and_generate_train_set_with_specified_M_and_R(data_filename, num_of_movies, num_of_rates, delimiter)\n",
    "        train = generate_mimic_data_train_set_with_specified_M_and_R(num_of_movies, num_of_rates)\n",
    "        print 'preparing training set done.'\n",
    "        print 'len(train):', len(train)\n",
    "\n",
    "        para = {'data': train, \n",
    "            'model_name': 'main_model',\n",
    "            'num_features': s,\n",
    "            'min_count': mc,\n",
    "            'window': w,\n",
    "            'iter': para_iter,\n",
    "            'batch_words': batch_words,\n",
    "        }\n",
    "        ##\n",
    "        print \"currently, num_of_movies=%d, num_of_rates=%d.\" % (num_of_movies, num_of_rates)\n",
    "        \n",
    "        #starttime = datetime.datetime.now()             # start timing\n",
    "        starttime = time.time()\n",
    "        train_a_model(para)\n",
    "\n",
    "        #endtime = datetime.datetime.now()               # stop timing\n",
    "        endtime = time.time()               # stop timing\n",
    "        \n",
    "        #interval = (endtime - starttime).seconds\n",
    "        interval = endtime - starttime\n",
    "        print 'interval: %g' % (interval)\n",
    "        \n",
    "        metric.append((num_of_movies, num_of_rates, interval))\n",
    "        \n",
    "        #break\n",
    "    #break\n",
    "for x in metric:\n",
    "    print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as font_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEKCAYAAADaa8itAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZi2CzAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa6d66d6c>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "values = [x[2] for x in metric]\n",
    "indexes = [x[1] for x in metric]\n",
    "labels=[\"%.2f\" % x for x in values]\n",
    "\n",
    "df = pd.DataFrame( data=values, index=indexes, )\n",
    "\n",
    "\n",
    "ax = df.plot(legend=False, marker='o')\n",
    "#legend = ax.legend()\n",
    "#font = font_manager.FontProperties(fname='/home/wsyj/Downloads/simsun.ttc')\n",
    "#\n",
    "#for text in legend.texts:\n",
    "#    text.set_font_properties(font)\n",
    "\n",
    "#ax.get_legend().set_title('1')\n",
    "\n",
    "\n",
    "for step, (label, x, y) in enumerate(zip(labels, indexes, values)):\n",
    "    #plt.annotate(\n",
    "    #    label,\n",
    "    #    xy=(x, y), xytext=(-20, 20),\n",
    "    #    textcoords='offset points', ha='right', va='bottom',\n",
    "    #    bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.5),\n",
    "    #    arrowprops=dict(arrowstyle = '->', connectionstyle='arc3,rad=0'))  # <== fancy annotation\n",
    "    \n",
    "    if 0 == step:\n",
    "        plt.annotate(\n",
    "            label,\n",
    "            xy=(x, y),\n",
    "            xytext=(5, -5),\n",
    "            textcoords='offset points', ha='left', va='bottom',)\n",
    "    else:\n",
    "        plt.annotate(\n",
    "            label,\n",
    "            xy=(x, y),\n",
    "            xytext=(0, -1),\n",
    "            textcoords='offset points', ha='right', va='bottom',)\n",
    "    \n",
    "plt.ylabel(u'(s)', fontproperties=font) \n",
    "plt.xlabel(u'', fontproperties=font)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
